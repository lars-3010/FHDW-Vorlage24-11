{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "titlepage-logo: img/fhdw.png\n",
        "Organisation: FHDW Bielefeld\n",
        "Studiengang: Wirtschaftsinformatik - Software Engineering\n",
        "Dokumententyp: Praxisarbeit\n",
        "Titel: Implementierung und Weiterentwicklung eines LLM-basierten Fehlererklärungssystems zur intelligenten Systemverbesserung\n",
        "Verfasser: |-\n",
        "  \\textbf{Lars Boes}\\\n",
        "  Schillerstraße 2c\\\n",
        "  53489 Sinzig\n",
        "Pruefer: Yvonne Gorniak\n",
        "Abgabedatum: 03.03.2025\n",
        "Autor: Lars Boes\n",
        "AutorUnterschrift: img/LarsBoes.png\n",
        "Ort: Valencia\n",
        "Kooperationsunternehmen: Deutsche Telekom Technik GmbH\n",
        "jupyter: python3\n",
        "format:\n",
        "  pdf:\n",
        "    documentclass: scrartcl\n",
        "    default: true\n",
        "    sperrvermerk: false\n",
        "    gendervermerk: true\n",
        "    glossar: true\n",
        "    keep-tex: true\n",
        "    latex-tinytex: false\n",
        "    classoption:\n",
        "      - numbers=noenddot\n",
        "      - listof=totoc\n",
        "  html:\n",
        "    lang: de\n",
        "---\n",
        "\n",
        "\n",
        "<!-- Das Dokument beginnt hier: -->\n",
        "\n",
        "<!-- Mittels include-Anweisungen werden weitere qmd-Dateien eingebunden -->\n",
        "\n",
        "\n",
        "# Einleitung & Kontext\n",
        "\n",
        "```{=latex}\n",
        "\\setcounter{figure}{0}\n",
        "\\setcounter{table}{0}\n",
        "```\n",
        "\n",
        "## Problemstellung\n",
        "\n",
        "Die zunehmende Komplexität moderner Cloud-Infrastrukturen führt zu einer wachsenden Herausforderung im Bereich des Deployment-Managements. Mit der Transformation zu containerisierten, microservice-basierten Architekturen steigt die Anzahl der Komponenten, Abhängigkeiten und möglichen Fehlerquellen exponentiell. Die Fehlerbehebung bei fehlgeschlagenen Deployments gestaltet sich oft schwierig, da die generierten Fehlermeldungen technisch detailliert und für Benutzer ohne tiefgreifende Systemkenntnisse schwer verständlich sind (Laigner et al., 2021; Oyekunle et al., 2024; Abbildung A.1);\n",
        "\n",
        "Diese Herausforderung führt zu erhöhtem Supportaufwand, verlängerten Lösungszeiten, reduzierter Produktivität und mangelnder Transparenz bezüglich der Fehlerursachen. In modernen verteilten Systemarchitekturen ist eine einzelne Fehlermeldung häufig das Resultat komplexer Interaktionen zwischen verschiedenen Systemkomponenten, was die Diagnose zusätzlich erschwert (Tzanettis et al., 2022).\n",
        "\n",
        "## Motivation\n",
        "\n",
        "Die Bewältigung dieser Herausforderung ist aus mehreren Gründen von entscheidender Bedeutung:\n",
        "\n",
        "**Wachsende Komplexität:** Moderne Microservice-Architekturen bestehen oft aus Hunderten von Services, was die Fehlerdiagnose erheblich erschwert. Die Anzahl der potenziellen Fehlerquellen steigt dabei nicht linear, sondern exponentiell mit der Anzahl der interagierenden Komponenten (Oyekunle et al., 2024; Saurabh et al., 2024).\n",
        "\n",
        "**Erhöhte Transparenz:** Bessere Erklärungen schaffen Transparenz und Vertrauen in die Plattform, besonders in komplexen, verteilten Systemen, wo die Ursache-Wirkungs-Beziehungen oft nicht unmittelbar ersichtlich sind und erhöhen somit auch die Benutzererfahrung (Dash, 2024; Dhoopati, 2023).\n",
        "\n",
        "## Warum LLMs?\n",
        "\n",
        "Large Language Models (LLMs) bieten für diese Herausforderung entscheidende Vorteile gegenüber traditionellen Ansätzen:\n",
        "\n",
        "-   **Verarbeitung natürlicher Sprache:** LLMs können unstrukturierte Fehlermeldungen interpretieren und in verständliche Erklärungen übersetzen (Brown et al., 2020; Wang et al., 2023).\n",
        "\n",
        "-   **Adaptivität:** Im Gegensatz zu regelbasierten Systemen können LLMs mit der Variabilität und Dynamik moderner Fehlerszenarien umgehen (Mao et al., 2024).\n",
        "\n",
        "-   **Skalierbarkeit:** LLMs können mit einer wachsenden Anzahl und Vielfalt von Fehlermeldungen umgehen, ohne manuelle Anpassungen zu erfordern (Alibakhsh, 2023).\n",
        "\n",
        "-   **Lernfähigkeit:** Sie haben das Potenzial, aus Feedback zu lernen und ihre Erklärungen kontinuierlich zu verbessern (Ouyang et al., 2022; Stiennon et al., 2020). Diese Eigenschaften machen LLMs deutlich überlegen gegenüber traditionellen Ansätzen, die mit der Komplexität moderner Cloud-Umgebungen oft überfordert sind. Die Fähigkeit, kontextbezogene Erklärungen zu generieren, adressiert direkt das Problem technisch komplexer Fehlermeldungen (Talukdar & Biswas, 2023).\n",
        "\n",
        "## Projektkontext\n",
        "\n",
        "Diese Arbeit konzentriert sich auf das **CAS** der Deutschen Telekom, eine Plattform zur automatisierten Bereitstellung und Verwaltung von Cloud-Ressourcen. Das entwickelte CASGPT-Feature erweitert dieses System, um Benutzern mit unterschiedlichen Erfahrungsniveaus verständliche Erklärungen für technische Fehlermeldungen in natürlicher Sprache zu bieten. Die Implementierung und Weiterentwicklung folgt dem Feed-Forward/Feed-Backward-Prinzip, bei dem ein initialer Design-Ansatz durch systematische Analyse und Feedback kontinuierlich verbessert wird. Dieser Ansatz harmoniert mit der Design Science Research(DSR) Methodik zur Entwicklung innovativer IT-Artefakte (Hevner et al., 2004; Engström et al., 2020). Die Integration des CASGPT-Features stellt einen konkreten Anwendungsfall für die Nutzung von LLMs in Enterprise-Umgebungen dar und bietet einen praxisnahen Kontext für die Erforschung der Evolution zu einem selbstlernenden System (Devaraju, 2024).\n",
        "\n",
        "## Forschungsziel\n",
        "\n",
        "**Hauptforschungsfrage:** \"Wie kann ein erfolgreich in ein Enterprise-System integriertes LLM-basiertes Fehlererklärungssystem durch systematische Analyse und Feedback zu einem selbstlernenden System evolvieren?\"\n",
        "\n",
        "**Unterforschungsfragen:**\n",
        "\n",
        "1\\. Welche Grundlagen und Anforderungen sind für eine erfolgreiche Integration von LLMs zur Fehlererklärung in Enterprise-Systeme notwendig?\n",
        "\n",
        "2\\. Wie können Fehlermuster und Systemfeedback systematisch für eine autonome Systemevolution genutzt werden?\n",
        "\n",
        "3\\. Welche Architekturkonzepte ermöglichen den Übergang von einem reaktiven zu einem proaktiven, selbstlernenden System?\n",
        "\n",
        "**Umfang und Abgrenzung:** Diese Forschung konzentriert sich auf Deployment-Fehler innerhalb des CAS-Systems. Sie umfasst die praktische Implementierung eines Prototyps und die konzeptionelle Ausarbeitung eines evolutionären Entwicklungskonzepts. Die Arbeit leistet einen Beitrag zum Verständnis der systematischen Evolution von KI-gestützten Assistenzsystemen in Unternehmenssystemen (Perron et al., 2025) und folgt dem iterativen Prozess von Design Science Research (Venable et al., 2016).\n",
        "\n",
        "\n",
        "# Theoretische Grundlagen\n",
        "\n",
        "## Large Language Models im Enterprise-Kontext\n",
        "\n",
        "LLMs, basierend auf der Transformer-Architektur (Vaswani et al., 2017), bieten durch ihre Fähigkeit, natürliche Sprache zu verstehen und zu generieren, neue Möglichkeiten für Unternehmensanwendungen (Brown et al., 2020). Für die Entwicklung eines Fehlererklärungssystems sind drei Eigenschaften von LLMs von besonderer Bedeutung: Kontextverständnis, Generalisierungsfähigkeit und Adaptivität (Törnberg, 2024). LLMs können komplexe Zusammenhänge in technischen Fehlermeldungen erfassen und interpretieren, bekannte Muster auf neue Fehlerszenarien übertragen und sich durch gezieltes Prompt Engineering an domänenspezifische Aufgaben anpassen (Wang et al., 2023; Kumar et al., 2025). Die Integration von LLMs in Enterprise-Systeme eröffnet das Potenzial zur Automatisierung, verbesserten Benutzererfahrung, Wissensverteilung, gesteigerter Integration und Skalierbarkeit (Alibakhsh, 2023; Devaraju, 2024). Gleichzeitig sind Herausforderungen wie Sicherheit, Ressourcenbedarf, Datenschutz, Interpretierbarkeit und Wartbarkeit zu adressieren (Alibakhsh, 2023; Chandramouli, 2022; Dhoopati, 2023). Eine detaillierte Gegenüberstellung dieser Chancen und Herausforderungen findet ist verfügbar (Tabelle A.4).\n",
        "\n",
        "Trotz ihrer Stärken weisen LLMs zwei kritische Limitationen auf, die für Fehlererklärungssysteme besonders relevant sind:\n",
        "\n",
        "1\\. **Halluzinationen:** LLMs können technisch plausibel klingende, aber faktisch falsche Informationen generieren (Orgad et al., 2024). Dies ist besonders problematisch bei technischen Fehlererklärungen, da fehlerhafte Lösungsvorschläge zu weiteren Problemen führen können. Ein konkretes Beispiel wäre die Identifikation nicht existierender Konfigurationsparameter oder das Empfehlen nicht verfügbarer API-Aufrufe. Aktuelle Forschungen zeigen, dass LLMs oft \"mehr wissen als sie zeigen\" – sie besitzen intern korrekte Repräsentationen, produzieren aber dennoch falsche Ausgaben, was das Vertrauen in LLM-basierte Systeme beeinträchtigen kann.\n",
        "\n",
        "2\\. **Mangelndes Systemkontextwissen:** LLMs fehlt spezifisches Wissen über die Systemarchitektur, Komponenten und deren Interaktionen im jeweiligen Enterprise-System (Wang et al., 2023; Wrick Talukdar & Biswas, 2023). Ohne diesen Kontext können LLMs nur allgemeine Erklärungen liefern, die möglicherweise nicht auf die spezifischen Umstände des Fehlers eingehen.\n",
        "\n",
        "## Ansätze zur Fehlererklärung\n",
        "\n",
        "Traditionelle Ansätze zur Fehlerbehandlung, wie statische Fehlercodes und umfangreiche Dokumentationen, stoßen in komplexen, dynamischen Systemen an ihre Grenzen. Regelbasierte Systeme bieten zwar Präzision bei bekannten Fehlern, sind aber unflexibel gegenüber neuen Fehlertypen und erfordern hohen manuellen Aufwand (Tabelle A.5). Im Gegensatz dazu bieten KI-basierte Ansätze, insbesondere LLMs, eine höhere Flexibilität und Adaptivität. Sie können aus unstrukturierten Fehlermeldungen relevante Informationen extrahieren, natürlichsprachliche Erklärungen generieren und sich potenziell an neue Fehlersituationen anpassen (Sain et al., 2024, Ahmed et al., 2023, Chen et al., 2023, Zhang et al., 2024). Die systematische Kategorisierung von Fehlern ist ein wichtiger Schritt, um die Effizienz der Fehlerbehandlung zu steigern (Abdallah, 2024; Agrawal, 2016; Ahmed, 2023). Durch die Identifikation wiederkehrender Fehlermuster können Ursachen schneller erkannt, Fehler priorisiert und gezielte Lösungsansätze entwickelt werden (Wang et al., 2022; Li et al., 2024). Sie ermöglicht zudem verbesserte Ursachenerkennung, effizientere Fehlerbehandlung, sinnvolle Prioritisierung und die proaktive Erkennung von Fehlermustern. (Vorobyov et al., 2021).\n",
        "\n",
        "## Prompt Engineering\n",
        "\n",
        "Prompt Engineering ist der Schlüssel zur effektiven Nutzung von LLMs (White et al., 2023; Cheng et al., 2024). Es umfasst die systematische Gestaltung von Eingabeaufforderungen, um das Verhalten des LLM gezielt zu steuern und qualitativ hochwertige Ausgaben zu erzielen (Törnberg, 2024). Grundlegende Prinzipien für erfolgreiches Prompt Engineering sind Klarheit, Spezifität, Strukturierung, Kontextualisierung, Few-Shot Learning und Chain-of-Thought-Prompting (Brown et al., 2020; Wei et al., 2022; White et al., 2023). Darüber hinaus existieren spezifische Prompt-Patterns, die als wiederverwendbare Bausteine für komplexere Interaktionen dienen können (White et al., 2023).\n",
        "\n",
        "Besonders relevant für Fehlererklärungssysteme sind:\n",
        "\n",
        "-   Das **Persona Pattern**, das dem LLM eine spezifische Rolle als Experte für Fehlererklärungen zuweist\n",
        "\n",
        "-   Das **Template Pattern**, das eine strukturierte Ausgabe mit Ursache, Auswirkung und Lösungsvorschlägen vorgibt\n",
        "\n",
        "-   Das **Context Enhancement Pattern**, das domänenspezifisches Wissen in den Prompt integriert\n",
        "\n",
        "-   Das **Cognitive Verifier Pattern**, das das LLM zur Selbstüberprüfung seiner Antworten auffordert, um Halluzinationen zu reduzieren\n",
        "\n",
        "-   Das **Chain-of-Thought Pattern**, das schrittweises Denken fördert und die Reasoning-Fähigkeiten verbessert\n",
        "\n",
        "Eine detaillierte Übersicht dieser Patterns wurde zusammengestellt (Tabelle A.6). Für technische Fehlererklärungen sind insbesondere die Unterscheidung zwischen System- und Benutzer-Prompt, die Klassifizierung von Fehlertypen und ein strukturiertes Ausgabeformat entscheidend (Vatsal & Dubey, 2024; White et al., 2023). Ein gut gestalteter System-Prompt definiert die Rolle und das erwartete Verhalten des LLM, während der Benutzer-Prompt die spezifische Fehlermeldung und relevanten Kontext enthält. Dieser iterative Prozess aus Design, Evaluation und Verbesserung entspricht dem Feed-Forward/Feed-Backward-Paradigma und ermöglicht die systematische Evolution des Systems (Bae et al., 2024).\n",
        "\n",
        "## Selbstlernende Systeme und Feed-Forward/Feed-Backward\n",
        "\n",
        "Der MAPE-K-Zyklus (Monitor-Analyze-Plan-Execute-Knowledge) bietet ein strukturiertes Framework für selbstadaptive Systeme, indem er kontinuierliche Überwachung, Analyse, Planung und Ausführung von Anpassungen ermöglicht (Cheng et al., 2009). Diese Struktur harmoniert mit dem Feed-Forward/Feed-Backward-Ansatz, da sie einen geschlossenen Regelkreis für kontinuierliches Lernen und Anpassen implementiert. Eine detaillierte Beschreibung der MAPE-K-Komponenten im Kontext von CASGPT wurde entwickelt (Tabelle A.7). Feedback-Schleifen ermöglichen die systematische Verbesserung aus Erfahrungen (Kang & Meira-Goes, 2022), während Human-in-the-Loop-Ansätze menschliches Expertenwissen in den Lernprozess integrieren (Wu et al., 2022; Stiennon et al., 2020). Für den Übergang von einem reaktiven zu einem proaktiven System sind zwei Mustererkennungstechniken besonders relevant: Das Clustering von Fehlermeldungen ermöglicht die Identifikation wiederkehrender Muster (Vorobyov et al., 2021), während Association Rule Mining Konfigurationsabhängigkeiten erkennen und für proaktive Konfigurationsvalidierungen nutzen kann (Wang et al., 2022; Li et al., 2024). Diese Techniken, kombiniert mit dem MAPE-K-Framework, bilden die Grundlage für die systematische Evolution eines reaktiven Fehlererklärungssystems zu einem proaktiven, selbstlernenden System.\n",
        "\n",
        "\n",
        "# Methodisches Vorgehen\n",
        "\n",
        "## Forschungsansatz: Design Science Research\n",
        "\n",
        "Um die in der Hauptforschungsfrage adressierte Evolution zu einem selbstlernenden System methodisch fundiert zu untersuchen, wird Design Science Research (DSR) als übergeordneter Forschungsrahmen gewählt. DSR ermöglicht die Entwicklung und Evaluation innovativer IT-Artefakte in einem iterativen Prozess (Hevner et al., 2004; Peffers et al., 2007). Dieser iterative Charakter ist von zentraler Bedeutung für die Umsetzung des Feed-Forward/Feed-Backward-Konzepts, das den Kern dieser Arbeit bildet.\n",
        "\n",
        "Die methodische Verankerung in DSR spiegelt sich in der Integration des Feed-Forward/Feed-Backward-Ansatzes in die drei DSR-Zyklen wider (Tabelle 1; Hevner, 2007):\n",
        "\n",
        "| **DSR-Zyklus** | **Feed-Forward** | **Feed-Backward** |\n",
        "|------------------------|------------------------|------------------------|\n",
        "| Relevanz-Zyklus | Identifikation des Problems unverständlicher Fehlermeldungen | Überprüfung der Erfüllung der identifizierten Anforderungen |\n",
        "| Design-Zyklus | Entwicklung des CASGPT-Systems | Iterative Verbesserung basierend auf Evaluationsergebnissen |\n",
        "| Rigor-Zyklus | Anwendung vorhandenen Wissens zu LLMs | Beitrag neuer Erkenntnisse zur LLM-Integration |\n",
        "\n",
        ": Integration von DSR-Zyklen und Feed-Forward/Feed-Backward-Ansatz\n",
        "\n",
        "Die Evaluation orientiert sich am Framework for Evaluation in Design Science (FEDS). Dabei wird, dem Feed-Backward-Gedanken folgend, eine formative, naturalistische Evaluierungsstrategie gewählt, um qualitative Rückmeldungen von Experten in einer realen Umgebung zu erhalten und in die Weiterentwicklung des Systems einfließen zu lassen. (Venable et al., 2016)\n",
        "\n",
        "## Forschungsdesign\n",
        "\n",
        "### Zweiphasiger Ansatz und iterativer Prozess\n",
        "\n",
        "Diese Forschung verfolgt einen zweiphasigen Ansatz, der den Feed-Forward/Feed-Backward-Kreislauf vollständig abbildet:\n",
        "\n",
        "1.  **Phase 1: Implementierung (Feed-Forward)**\n",
        "    -   Konzeption und Implementierung des CASGPT-Features basierend auf theoretischen Grundlagen\n",
        "    -   Technische Integration von LLMs, Prompt Engineering und Benutzeroberfläche\n",
        "    -   Dokumentation der implementierten Systemarchitektur und ihrer Komponenten\n",
        "2.  **Phase 2: Evolution (Feed-Backward → Feed-Forward)**\n",
        "    -   Untersuchung der Weiterentwicklungsmöglichkeiten zu einem selbstlernenden System\n",
        "    -   Basiert auf systematischer Evaluation und Feedbackanalyse\n",
        "    -   Entwicklung eines evolutionären Weiterentwicklungskonzepts für proaktive Fehlererklärung\n",
        "\n",
        "Der Entwicklungsprozess ist bewusst iterativ gestaltet, wobei Feedback aus Tests und Experteninterviews kontinuierlich in Designverbesserungen einfließt. Dieser Ansatz entspricht der Verschränkung von Entwicklung, Intervention und Evaluation im Design Science Kontext (Sein et al., 2011).\n",
        "\n",
        "## Datenerhebung und -analyse\n",
        "\n",
        "### Implementierungsdaten\n",
        "\n",
        "Die initiale Implementierung von CASGPT stützte sich auf verschiedene Datenquellen:\n",
        "\n",
        "-   Systemdokumentation und Fehlerprotokolle des CAS-Systems\n",
        "-   Expertenwissen des Entwicklungsteams\n",
        "-   Erkenntnisse aus der Forschungsliteratur zu LLMs und Prompt Engineering\n",
        "\n",
        "### Evaluierung durch Experteninterviews\n",
        "\n",
        "Als primäre Evaluierungsmethode wurden halbstrukturierte Interviews mit drei Schlüsselpersonen durchgeführt, die unterschiedliche Perspektiven auf das System repräsentieren:\n",
        "\n",
        "-   **Teamleiter (Product Owner):** Strategische Perspektive (Projektziele und Vision)\n",
        "-   **Full-Stack-Entwickler:** Technische Perspektive (Implementierung und Integration)\n",
        "-   **DevOps Engineer:** Operative Perspektive (Systemstabilität und Fehlerbehebung)\n",
        "\n",
        "Diese multiperspektivische Herangehensweise folgt den Empfehlungen zur Planung und Durchführung von Experteninterviews in der Informationssystemforschung (Hevner et al., 2004; Engström et al., 2020).\n",
        "\n",
        "**Interviewmethodik:** Die Interviews folgten einem halbstrukturierten Format mit einem dreistufigen Aufbau:\n",
        "\n",
        "1.  **Einführende Fragen** zur Rolle und Erfahrung\n",
        "2.  **Hauptfragenblock** zu zentralen Themenbereichen (Qualität der Erklärungen, Workflow-Integration, technische Aspekte)\n",
        "3.  **Abschlussfragen** zum Gesamteindruck und zu Verbesserungsvorschlägen\n",
        "\n",
        "Dieser Ansatz ermöglichte sowohl die systematische Abdeckung der Forschungsfragen als auch die Exploration unerwarteter Einsichten. Die Interviews dauerten jeweils 45-60 Minuten und wurden protokolliert. Der vollständige Interviewleitfaden ist in Anhang A dokumentiert.\n",
        "\n",
        "### Qualitative Inhaltsanalyse\n",
        "\n",
        "Die Auswertung der Interviews erfolgte mittels qualitativer Inhaltsanalyse (Mayring, 2014), wobei ein kombiniert deduktiv-induktives Vorgehen angewandt wurde. Zunächst wurden auf Basis der Forschungsfragen und des theoretischen Rahmens deduktiv Hauptkategorien abgeleitet. In einem zweiten Schritt erfolgte die induktive Kategorienbildung aus dem Material heraus, wodurch unerwartete Einsichten und Themen identifiziert werden konnten. Diese methodische Triangulation ermöglichte sowohl die systematische Prüfung theoriegeleiteter Aspekte als auch die Entdeckung neuer, für die Evolution des Systems relevanter Erkenntnisse.\n",
        "\n",
        "Der Analyseprozess umfasste folgende Schritte:\n",
        "\n",
        "1.  **Kodierung:** Analyse der Interviewprotokolle durch systematische Zuordnung von Textstellen zu Kategorien\n",
        "2.  **Thematische Analyse:** Identifikation von Mustern, Schlüsselthemen und Beziehungen zwischen Konzepten\n",
        "3.  **Triangulation:** Vergleich und Gegenüberstellung der verschiedenen Perspektiven für ein umfassendes Bild\n",
        "\n",
        "Diese systematische Auswertung gewährleistet eine methodisch fundierte Ableitung von Erkenntnissen aus dem qualitativen Material. Die Triangulation der verschiedenen Perspektiven stärkt zusätzlich die Validität der Ergebnisse (Engström et al., 2020). Das vollständige Codebook mit Definitionen und Beispielen ist in Anhang B dokumentiert Die aus der Analyse gewonnenen Erkenntnisse bilden die Grundlage für die Konzeption des evolutionären Weiterentwicklungsansatzes für CASGPT.\n",
        "\n",
        "## Methodische Reflexion\n",
        "\n",
        "Bei der Durchführung wurden ethische Aspekte gemäß den Richtlinien der Deutschen Telekom und der DSGVO berücksichtigt. Die wesentlichen methodischen Limitationen umfassen:\n",
        "\n",
        "-   **Begrenzte Teilnehmerzahl**: Die Stichprobe von drei Experten wurde durch gezielt unterschiedliche Perspektiven (strategisch, technisch, operativ) kompensiert.\n",
        "-   **Qualitative Natur**: Die primär auf Experteneinschätzungen basierende Evaluation könnte in zukünftigen Studien durch quantitative Nutzungsdaten ergänzt werden.\n",
        "-   **Zeitlicher Rahmen**: Die Evaluation bezieht sich auf einen spezifischen Zeitpunkt und reflektiert nicht die langfristige Systemnutzung.\n",
        "\n",
        "Diese Limitationen sind für qualitative DSR-Projekte in frühen Entwicklungsphasen typisch (Hevner & Chatterjee, 2010) und werden bei der Interpretation entsprechend berücksichtigt.\n",
        "\n",
        "\n",
        "# System und Implementierung\n",
        "\n",
        "## CAS-Systemüberblick\n",
        "\n",
        "**Problemstellung:** Die in der Einleitung ausführlich dargestellte Problematik unverständlicher Fehlermeldungen manifestiert sich besonders im Cloud Automation System (CAS) der Deutschen Telekom, das die Bereitstellung von Cloud-Ressourcen automatisiert.\n",
        "\n",
        "**Zielbenutzer:** Die primären Benutzer von CAS sind DevOps-Ingenieure und Anwendungsentwickler mit heterogenen Erfahrungsniveaus. Während einige Experten mit dem Debugging komplexer Systemfehler vertraut sind, benötigen andere Benutzer zusätzliche Unterstützung bei der Fehlerbehebung. Diese Heterogenität stellte eine besondere Herausforderung bei der Entwicklung des \"Explain by AI\"-Features dar, da die Erklärungen für Benutzer mit unterschiedlichem technischen Hintergrund verständlich sein müssen.\n",
        "\n",
        "## Das \"Explain by AI\"-Feature (CASGPT)\n",
        "\n",
        "### Konzeption und User Journey\n",
        "\n",
        "Das \"Explain by AI\"-Feature (CASGPT) wurde konzipiert, um das Problem unverständlicher Fehlermeldungen zu adressieren und folgt dem Feed-Forward-Ansatz, bei dem theoretische Überlegungen zu LLMs und Prompt Engineering in eine praktische Implementierung überführt werden. Die typische Benutzerinteraktion umfasst das Auftreten eines Fehlers während des Deployments, das Anklicken der \"Explain by AI\"-Schaltfläche neben der Fehlermeldung, die automatische Analyse und Kategorisierung durch das System und die Bereitstellung einer verständlichen Erklärung in natürlicher Sprache. Diese enthält Informationen zur Ursache, potenziellen Auswirkungen und möglichen Lösungsansätzen, was dem Benutzer ermöglicht, gezielt Korrekturmaßnahmen zu ergreifen. (Abbildung A.1)\n",
        "\n",
        "### Funktionaler Umfang und Benutzeroberfläche\n",
        "\n",
        "CASGPT ist nahtlos in die bestehende CAS-Benutzeroberfläche integriert und erscheint als Schaltfläche \"Explain by AI\" neben Fehlermeldungen in der Deployment-Fortschrittsanzeige (ProgressView). Die Hauptfunktionalitäten umfassen die automatische Fehleranalyse, natürlichsprachliche Erklärung, strukturierte Ausgabe und kontextspezifische Informationen basierend auf der identifizierten Fehlerkategorie. Die Benutzeroberfläche wurde bewusst einfach gehalten, um die Benutzerakzeptanz zu fördern.\n",
        "\n",
        "## Systemarchitektur\n",
        "\n",
        "### Architekturüberblick\n",
        "\n",
        "CASGPT ist als Microservice-Architektur implementiert, wobei die einzelnen Komponenten lose gekoppelt sind und über definierte Schnittstellen kommunizieren. Diese Architekturentscheidung ermöglicht Skalierbarkeit, Wartbarkeit und Fehlertoleranz (Oyekunle et al., 2024; Laigner et al., 2021) und unterstützt den iterativen Feed-Forward/Feed-Backward-Ansatz durch die Möglichkeit, einzelne Komponenten unabhängig zu aktualisieren. Der Kommunikationsfluss umfasst drei Hauptpfade: vom Frontend (Angular) zum Backend (Python/FastAPI), vom Backend zum LLM-Service (Azure OpenAI) und zurück vom Backend zum Frontend zur Anzeige der generierten Erklärung (Abbildung A.2).\n",
        "\n",
        "### Komponentenbeschreibung\n",
        "\n",
        "**Frontend (Angular)**\n",
        "\n",
        "-   Erweiterte `ProgressComponent` zur Integration der \"Explain by AI\"-Funktionalität und State Management des Erklärungsstatus\n",
        "\n",
        "-   Erweiterte `ApiService` für die Kommunikation mit dem Backend **Backend (Python/FastAPI)**\n",
        "\n",
        "-   `Gateway` mit neuem Endpunkt für CASGPT-Anfragen\n",
        "\n",
        "-   `ErrorExplanationHandler` als Kernkomponente für Fehlerverarbeitung (Code A.11)\n",
        "\n",
        "-   `PromptConfig` für die Verwaltung von Prompts und Kategorien (Code A.10)\n",
        "\n",
        "**LLM-Integration (Azure OpenAI):** Intern gehostete GPT-4-Instanz mit sicherer Verbindung über Azure OpenAI API Diese lose gekoppelten Komponenten kommunizieren über definierte Schnittstellen und unterstützen dadurch den iterativen Feed-Forward/Feed-Backward-Ansatz.\n",
        "\n",
        "### Datenfluss und Sequenz\n",
        "\n",
        "![Datenfluss Sequenzdiagramm](img/DatenflussSequenzdiagramm.png)\n",
        "\n",
        "Der detaillierte Datenfluss bei einer typischen Anfrage umfasst acht Schritte: von der Benutzerinteraktion über die Extraktion der Fehlermeldung, die HTTP-Anfrage, die Weiterleitung ans Backend, die Fehleranalyse und Prompt-Erstellung, die LLM-Interaktion bis zur Rückgabe und Anzeige der Erklärung. Dieser Prozess dauert typischerweise 3-5 Sekunden, was als akzeptable Reaktionszeit eingestuft wurde (Abbildung 1).\n",
        "\n",
        "### Entwicklungs- und Zielumgebung\n",
        "\n",
        "Das CAS-System selbst ist in einem Kubernetes-Cluster deployed, während CASGPT derzeit als Prototyp in einer lokalen Entwicklungsumgebung läuft. Die lokale Entwicklung erfolgt mithilfe von Docker-Containern, um die Portabilität zu gewährleisten und eine konsistente Entwicklungsumgebung für alle Teammitglieder zu schaffen. Die Fehlermeldungen werden vom internen Life Cycle Management (LCM) generiert, das für die Orchestrierung des gesamten Deployment-Prozesses verantwortlich ist. Für die zukünftige vollständige Integration ist ein Deployment in der bestehenden Kubernetes-Infrastruktur geplant.\n",
        "\n",
        "## Prompt-Engineering und -Konfiguration\n",
        "\n",
        "### Architektur der Prompt-Konfiguration\n",
        "\n",
        "Das Prompt-Engineering bildet das Herzstück des CASGPT-Systems und repräsentiert einen zentralen Feed-Forward-Aspekt der Implementierung. Die Prompt-Konfiguration ist als eigenständige Komponente (`PromptConfig`) implementiert, um eine klare Trennung der Verantwortlichkeiten zu gewährleisten und zukünftige Erweiterungen im Sinne des Feed-Forward/Feed-Backward-Paradigmas zu erleichtern (White et al., 2023). Der detaillierte Workflow des Prompt-Engineering-Prozesses veranschaulicht die Entwicklung von einer einfachen Erklärung hin zu einer ursachenabhängigen, mit Kategorien angereicherten und formatierten Erklärung (Abbildung A.3).\n",
        "\n",
        "Die Hauptklassen der Implementierung umfassen:\n",
        "\n",
        "-   **PromptConfig:** Zentrale Klasse für die Initialisierung der Konfiguration und die Bereitstellung von Methoden zur Generierung von System- und Error-Prompts\n",
        "\n",
        "-   **ErrorType (Enum):** Definition verschiedener Fehlertypen (System Error, User-Fixable Error, etc.)\n",
        "\n",
        "-   **ErrorCategory:** Repräsentation einer Fehlerkategorie mit zugehörigen Mustern, Kontext und Fehlertyp\n",
        "\n",
        "-   **ErrorPattern:** Definition eines Musters zur Erkennung einer Fehlerkategorie mit Gewichtungsfaktor\n",
        "\n",
        "-   **Message:** Repräsentation einer Nachricht mit Rolle und Inhalt für die LLM-Kommunikation\n",
        "\n",
        "![Prompt Flow Diagramm](img/PromptFlowDiagramm.png)\n",
        "\n",
        "Die Fehlerkategorisierung basiert auf einem Mustererkennungssystem mit regulären Ausdrücken und einem gewichteten Scoring-Mechanismus. Das System umfasst sieben Hauptkategorien typischer CAS-Fehler: Datenverarbeitung, Service-Verfügbarkeit, Konfiguration, Deployment, Netzwerk, Laufzeitausnahmen und eine allgemeine Kategorie. Durch die Analyse von Log-Dateien mit dem LLM Claude 3.5 Sonnet wurden die Fehlerkategorien ermittelt. Der Musterabgleich prüft die regulären Ausdrücke jeder Kategorie gegen die eingehende Fehlermeldung und berechnet einen Score basierend auf Gewichtung und Spezifität der Muster. Die Kategorie mit dem höchsten Score wird für die Fehlermeldung ausgewählt, wodurch eine präzise Kategorisierung und zielgerichtete Erklärungen ermöglicht werden (Vorobyov et al., 2021; Abbildung A2; Code A.10).\n",
        "\n",
        "### Prompt-Struktur\n",
        "\n",
        "Die Prompt-Struktur orientiert sich an Best Practices und ist in drei Hauptkomponenten unterteilt:\n",
        "\n",
        "1\\. **System Prompt:** Dieser Prompt legt die grundlegende Rolle und das erwartete Verhalten des LLM fest und bleibt über alle Anfragen hinweg konstant. Er definiert das LLM als Experten für Fehlererklärungen im Kontext der Deployment-Infrastruktur von CAS.\n",
        "\n",
        "2\\. **Error Prompts:** Diese Prompts werden dynamisch auf Basis der identifizierten Fehlerkategorie generiert. Sie enthalten die originale Fehlermeldung, die zugeordnete Kategorie, relevanten kategoriespezifischen Kontext und aus der Fehlermeldung extrahierte Schlüsselwörter.\n",
        "\n",
        "3\\. **Response Templates:** Diese Templates definieren die erwartete Struktur der LLM-Antwort. Sie variieren je nach Fehlertyp (z.B. Standard, Quick-Fix, User-Error), um sicherzustellen, dass die Erklärungen jeweils die relevantesten Informationen enthalten (Ursache, Auswirkung, Lösungsschritte).\n",
        "\n",
        "Das übergeordnete Ziel der Prompt-Gestaltung ist es, technische Konzepte auch für Benutzer mit unterschiedlichem Vorwissen verständlich zu machen und Fehlermeldungen in eine möglichst natürliche und zugängliche Sprache zu übersetzen. Der vollständige System Prompt sowie Beispiele für Error Prompts und Response Templates sind zur Referenz in Anhang C dokumentiert (Vatsal & Dubey, 2024; White et al., 2023; Code A.10).\n",
        "\n",
        "### Aktuelle Einschränkungen und Abgrenzung\n",
        "\n",
        "Die aktuelle Implementierung integriert bewusst keinen dynamischen, systemspezifischen Kontext in den Prompt-Engineering-Prozess. Diese Abgrenzung wurde vorgenommen, um den Implementierungsumfang realistisch zu halten, eine definierte Ausgangsbasis für die Evaluation zu schaffen und das Potenzial für Weiterentwicklung zu demonstrieren. Konkret fehlen der aktuellen Implementierung wichtige Kontextinformationen wie spezifische Konfigurationen der betroffenen Dienste, Versionsdetails der verwendeten Software und Container, Status abhängiger Komponenten sowie historische Fehlerinformationen für ähnliche Deployments. Diese fehlenden Kontextinformationen limitieren die Spezifität und Handlungsrelevanz der Erklärungen, was in den Experteninterviews als Hauptverbesserungspotential identifiziert wurde und einen zentralen Aspekt des evolutionären Weiterentwicklungskonzepts bildet.\n",
        "\n",
        "## Entwicklungsprozess\n",
        "\n",
        "Das Feature wurde iterativ entwickelt, wobei Feedback aus internen Demo-Tests und Diskussionen im Team kontinuierlich in die Designentscheidungen einfloss. Dieser iterative Prozess spiegelt den Feed-Forward/Feed-Backward-Ansatz wider: ein initiales Design basierend auf theoretischen Grundlagen (Feed-Forward) und kontinuierliche Verbesserung basierend auf frühem Feedback (Feed-Backward). Ein konkretes Beispiel für diesen iterativen Verbesserungsprozess ist die Evolution der Prompts von einfachen Anfragen (\"Explain this error message: {error_message}\") zu strukturierten, kontextspezifischen Prompts mit detaillierten Anweisungen und kategoriespezifischem Kontext (Abbildung A.3).\n",
        "\n",
        "## Technische Herausforderungen\n",
        "\n",
        "Bei der Implementierung von CASGPT waren zwei zentrale technische Herausforderungen zu bewältigen:\n",
        "\n",
        "**Integration in bestehende Systemkomponenten:** Die nahtlose Einbindung in die Architektur des CAS-Systems erforderte tiefgreifendes Verständnis der bestehenden Komponenten und Datenflüsse. Besonders die Erweiterung der ProgressComponent und des ApiService sowie die Integration in das Gateway unter Beibehaltung der Sicherheitsmechanismen stellten anspruchsvolle Aufgaben dar.\n",
        "\n",
        "**Prompt-Konfiguration:** Die Entwicklung eines effektiven Kategorisierungssystems mit Mustern für verschiedene Fehlertypen erforderte umfangreiche Analyse realer Fehlermeldungen. Die größte Herausforderung bestand darin, eine Balance zwischen generalisierten Erklärungen für diverse Fehler und spezifischen, handlungsrelevanten Informationen zu finden. Der iterative Ansatz zur Verfeinerung der Prompt-Konfiguration anhand von Testfällen mit realen Fehlermeldungen ermöglichte die schrittweise Optimierung der Erklärungsqualität.\n",
        "\n",
        "## Sicherheitsaspekte\n",
        "\n",
        "### Sicherheitsmaßnahmen\n",
        "\n",
        "Bei der Implementierung wurden verschiedene Sicherheitsmaßnahmen getroffen, um den Enterprise-Anforderungen gerecht zu werden:\n",
        "\n",
        "1\\. Nutzung eines intern gehosteten LLM in Schweden für Datensouveränität und DSGVO-Konformität\n",
        "\n",
        "2\\. direkte Extraktion der Fehlermeldungen aus Systemlogs zur Vermeidung von XSS-Schwachstellen\n",
        "\n",
        "3\\. Integration in bestehende Sicherheitsmechanismen des API-Gateways\n",
        "\n",
        "4\\. sichere Speicherung sensitiver Tokens in Vault.\n",
        "\n",
        "Diese Maßnahmen stellen sicher, dass CASGPT keine neuen Sicherheitsrisiken einführt.\n",
        "\n",
        "### Umgang mit LLM-Limitationen\n",
        "\n",
        "CASGPT implementiert mehrere gezielte Maßnahmen, um den diskutierten Limitationen zu begegnen:\n",
        "\n",
        "**Gegen Halluzinationen:** - Strukturierte Prompts mit klaren Antwortformaten\n",
        "\n",
        "-   Reflection Pattern zur kritischen Selbstreflexion des LLM\n",
        "\n",
        "-   Template Pattern zur Strukturierung der Ausgaben\n",
        "\n",
        "**Gegen mangelndes Systemkontextwissen:**\n",
        "\n",
        "-   Fehlerkategorisierung für kategoriespezifischen Kontext\n",
        "\n",
        "-   Kontextuelle Anreicherung durch Extraktion relevanter Informationen\n",
        "\n",
        "-   Bewusste Abgrenzung zur Schaffung einer definierten Evaluationsbasis\n",
        "\n",
        "Diese Gegenmaßnahmen bilden die Grundlage für die initiale Implementierung und werden im Rahmen der evolutionären Weiterentwicklung optimiert.\n",
        "\n",
        "\n",
        "# Evaluation und Analyse\n",
        "\n",
        "## Methodik der Evaluation\n",
        "\n",
        "Die Evaluation des CASGPT-Systems erfolgte mittels halbstrukturierter Experteninterviews mit drei Schlüsselpersonen: einem Product Owner (P), einem Full-Stack-Entwickler (M) und einem DevOps Engineer (D). Diese multiperspektivische Herangehensweise ermöglicht eine ganzheitliche Beurteilung des Systems (Engström et al., 2020).\n",
        "\n",
        "Die etwa 45-60-minütigen Interviews wurden protokolliert und mittels qualitativer Inhaltsanalyse ausgewertet (Mayring, 2014; Notizen A.12)). Die Analyse erfolgte durch ein kombiniert deduktiv-induktives Kodierungsverfahren, wobei zunächst theoriegeleitete Hauptkategorien definiert und anschließend induktiv weitere Kategorien aus dem Material entwickelt wurden.\n",
        "\n",
        "## Zentrale Evaluationsergebnisse\n",
        "\n",
        "Die qualitative Analyse der Interviews ergab mehrere zentrale Erkenntnisse:\n",
        "\n",
        "Der **Bedarf an systemspezifischem Kontext** wurde am häufigsten thematisiert (8 Nennungen), gefolgt vom **Mangel an Spezifität** in den Erklärungen (6 Nennungen) und dem wahrgenommenen **Potenzial des Systems** (6 Nennungen). Der **Beitrag zum Benutzerverständnis** wurde ebenfalls als wesentlicher positiver Aspekt hervorgehoben (5 Nennungen).\n",
        "\n",
        "Diese quantitative Verteilung deutet auf ein grundsätzlich wertvolles System hin, das durch die Integration von spezifischem Systemwissen deutlich verbessert werden könnte (Tabelle A.8).\n",
        "\n",
        "## Thematische Analyse und rollenspezifische Perspektiven\n",
        "\n",
        "### Systemkontext als Hauptlimitation\n",
        "\n",
        "Alle drei Experten identifizierten den mangelnden Systemkontext als zentrale Einschränkung:\n",
        "\n",
        "> \"Ja, die System Knowledge fehlt, die man in die Prompts einbauen sollte\" (D)\n",
        ">\n",
        "> \"Wenn System Knowledge (Wiki Dump) dem Model gegeben wird, hat es mehr Ahnung worum es geht\" (M)\n",
        "\n",
        "Der DevOps Engineer betonte den Bedarf an spezifischeren Handlungsempfehlungen, während der Full-Stack-Entwickler auf die technische Umsetzbarkeit durch Integration von Systemdokumentation fokussierte. Der Product Owner sah dies als Möglichkeit zur Erhöhung des Systemwerts.\n",
        "\n",
        "### Grundnutzen und Transparenz\n",
        "\n",
        "Trotz der identifizierten Einschränkungen bestätigten alle Interviews den Mehrwert des Systems:\n",
        "\n",
        "> \"Doch schon einiges an Hilfe, nicht jeder User weiß, was ein DSO ist\" (M)\n",
        ">\n",
        "> \"Wertschöpfung: für Menschen komisch wirkenden Fehler in natürliche Sprache übersetzen\" (P)\n",
        "\n",
        "Der Hauptwert liegt in der Übersetzungsleistung von technischen Details in verständliche Sprache und der damit verbundenen Transparenz und Vertrauensbildung.\n",
        "\n",
        "### Integration und Akzeptanz\n",
        "\n",
        "Die Integration des Features in den bestehenden Workflow wurde einheitlich positiv bewertet, wobei die nahtlose Implementierung in die Benutzeroberfläche und die Übereinstimmung mit den Nutzererwartungen hervorgehoben wurden. Der DevOps Engineer identifizierte die Antwortzeit als kritischen Faktor: \"Nicht zu hohe Latenz zwischen der Antwort... wenn man so ca. 5 Sekunden wartet ist's okay\" (D).\n",
        "\n",
        "### Entwicklungspotenzial\n",
        "\n",
        "Als konkrete Erweiterungsmöglichkeiten wurden vorgeschlagen:\n",
        "\n",
        "-   **BlueBox-übergreifender Wissenstransfer**: \"Wenn Fehler bei einer anderen BlueBox war, direkt in Prompt mit schreiben - das war übrigens der Fix\" (D)\n",
        "-   **Interaktives Chatfenster**: \"Weiterentwicklung: interaktiver: z.B. in die Erklärung ein Chatfenster → KI nochmal Nachfragen stellen\" (P)\n",
        "-   **Feedbackmechanismen**: \"Selbstlernend immer sinnvoll → Antwortqualität bewerten\" (M)\n",
        "\n",
        "\n",
        "# Evolutionäres Weiterentwicklungskonzept\n",
        "\n",
        "## Zielzustand und Wertbeitrag\n",
        "\n",
        "Der angestrebte Zielzustand entwickelt das aktuelle CASGPT von generischen Erklärungen (Wang et al., 2023) zu spezifischen, kontextbewussten Erklärungen; von statischer Prompt-Konfiguration zu kontinuierlicher, feedback-basierter Verbesserung (Ouyang et al., 2022); von reaktiver zu proaktiver, vorhersagebasierter Fehlerbehandlung (Ahmed et al., 2023); von einmaliger Erklärung zu dialogbasierter Interaktion (Wu et al., 2022); und von keiner Lernfähigkeit zu systematischem Feedback-basiertem Lernen (Li et al., 2021). Ein detaillierter Vergleich zwischen dem aktuellen Zustand und dem Zielzustand wurde erarbeitet (Tabelle A.9).\n",
        "\n",
        "Dieser Zielzustand verspricht mehrere konkrete Wertbeiträge:\n",
        "\n",
        "1\\. **Erhöhte Benutzerproduktivität** durch präzisere, kontextspezifische Erklärungen\n",
        "\n",
        "2\\. **Reduzierter Supportaufwand** durch verbesserte Selbsthilfe-Möglichkeiten\n",
        "\n",
        "3\\. **Verbesserte Systemzuverlässigkeit** durch proaktive Fehlervermeidung\n",
        "\n",
        "4\\. **Kontinuierliche Wissenserweiterung** als selbstverstärkender Lernprozess\n",
        "\n",
        "Dieser Zielstand orientiert sich an dem Rahmen des Feed-Forward/Feed-Backward-Ansatzes, der die gesamte CASGPT-Entwicklung charakterisiert.\n",
        "\n",
        "## Feed-Forward/Feed-Backward-Integration\n",
        "\n",
        "### MAPE-K-Schleife als strukturelles Rahmenwerk\n",
        "\n",
        "Um den Feed-Forward/Feed-Backward-Ansatz in ein operatives Designprinzip zu überführen, wird das MAPE-K-Framework (Monitor, Analyze, Plan, Execute, Knowledge) für selbstadaptive Systeme (Cheng et al., 2009) als strukturelles Rahmenwerk verwendet. Dieses Framework implementiert einen geschlossenen Regelkreis für kontinuierliches Lernen und integriert Feedback-Mechanismen in einen strukturierten Adaptionsprozess:\n",
        "\n",
        "-   **Monitor:** Sammlung von Fehlermeldungen, Benutzerfeedback und Systemmetriken\n",
        "\n",
        "-   **Analyze:** Musteranalyse, Fehlerkategorisierung und Feedbackauswertung\n",
        "\n",
        "-   **Plan:** Optimierung der Prompts und Erweiterung der Wissensbasis\n",
        "\n",
        "-   **Execute:** Anwendung optimierter Prompts und Integration neuen Wissens\n",
        "\n",
        "-   **Knowledge:** Zentrale Wissensbasis mit Systemkontext und Fehlermustern\n",
        "\n",
        "Der Knowledge-Bereich dient dabei als gemeinsame Grundlage für Feed-Forward (Anwendung von Wissen) und Feed-Backward (Integration neuen Wissens).\n",
        "\n",
        "### Feedback-Mechanismen als Kernelemente\n",
        "\n",
        "Basierend auf den Experteninterviews (M: \"selbstlernend immer sinnvoll → Antwortsqualität bewerten\") werden folgende Feedback-Mechanismen konzipiert:\n",
        "\n",
        "**1. Explizites Feedback:**\n",
        "\n",
        "-   **Qualitätsbewertung:** Einfaches Bewertungssystem (+/-) nach jeder Erklärung\n",
        "\n",
        "-   **Kategorisiertes Feedback:** Vorgegebene Kategorien wie \"Zu technisch\", \"Zu vage\"\n",
        "\n",
        "-   **Verbesserungsvorschläge:** Freitextfeld für konkrete Anregungen\n",
        "\n",
        "**2. Implizites Feedback:**\n",
        "\n",
        "-   **Wiederkehrende Fehler:** Automatische Erkennung von Fällen, in denen derselbe Fehler nach einer Erklärung erneut auftritt\n",
        "\n",
        "-   **Nutzungsstatistiken:** Analyse der Nutzungsmuster (z.B. Häufigkeit der Feature-Nutzung)\n",
        "\n",
        "### BlueBox-übergreifender Wissenstransfer\n",
        "\n",
        "Ein besonders effektiver Mechanismus zur Systemverbesserung ist die Übertragung von Lösungen zwischen verschiedenen BlueBoxes, wie vom DevOps Engineer hervorgehoben:\n",
        "\n",
        "> \"Wenn Fehler bei einer anderen BlueBox war, direkt in Prompt mit schreiben - das war übrigens der Fix → BlueBox kann das selber machen \\[...\\] Spart Zeit → weniger Supportaufwand bei selbem Fehler\" (D)\n",
        "\n",
        "Dieser Ansatz implementiert einen selbstverstärkenden Lernmechanismus durch:\n",
        "\n",
        "1\\. **Erfassung erfolgreicher Fixes:** Dokumentation erfolgreicher Fehlerbehebungen mit Kontext\n",
        "\n",
        "2\\. **Erkennung ähnlicher Fehler:** Automatische Identifikation von Ähnlichkeiten zu früheren Fehlern\n",
        "\n",
        "3\\. **Integration von Lösungswissen:** Wiederverwendung bewährter Lösungsansätze in neuen Kontexten\n",
        "\n",
        "## Systematische Analyse für proaktive Fehlervorhersage\n",
        "\n",
        "### Clustering von Fehlermeldungen\n",
        "\n",
        "Zur Identifikation ähnlicher Fehler wird ein Clustering-Ansatz implementiert, der die Grundlage für den BlueBox-übergreifenden Wissenstransfer bildet (Vorobyov et al., 2021):\n",
        "\n",
        "-   **Aufbereitung der Fehlertexte:** Entfernung variabler Elemente wie Zeitstempel und Tokenisierung\n",
        "\n",
        "-   **Gruppierung:** Anwendung von k-Means oder DBSCAN zur automatischen Cluster-Bildung\n",
        "\n",
        "-   **Anwendung für Prompt-Optimierung:** Entwicklung spezifischer Prompt-Templates für häufige Fehlerklassen\n",
        "\n",
        "Das Clustering ermöglicht eine klarere Unterscheidung zwischen nutzerseitigen und systemseitigen Fehlern – ein Aspekt, der in den Interviews als wichtig hervorgehoben wurde.\n",
        "\n",
        "### Association Rule Mining für Fehlervorhersage\n",
        "\n",
        "Association Rule Mining (ARM) dient zur Identifikation von Zusammenhängen zwischen Konfigurationsparametern und Fehlertypen (Wang et al., 2022; Li et al., 2024):\n",
        "\n",
        "-   **Regelextraktion:** Anwendung von Algorithmen wie Apriori oder FP-Growth\n",
        "\n",
        "-   **Praktische Anwendung:** Übersetzung der Regeln in verständliche Warnungen und Empfehlungen\n",
        "\n",
        "Durch die Kombination von Clustering und ARM können Fehlermuster systematisch identifiziert und für die Verbesserung des Systems genutzt werden, was direkt auf die zweite Unterforschungsfrage einzahlt.\n",
        "\n",
        "**Beispiel für Assoziationsregeln:**\n",
        "\n",
        "> `WENN (service_version=\"1.2.3\" UND network_config=\"internal\") DANN Wahrscheinlichkeit für Fehlertyp \"permission_denied\" = 78% EMPFEHLUNG: \"Überprüfen Sie die Berechtigungen vor dem Deployment\"`\n",
        "\n",
        "## Proaktive Fähigkeiten\n",
        "\n",
        "### Kontextsensitive Erklärungen\n",
        "\n",
        "Die Integration von Systemkontext in die Erklärungen bildet die Grundlage für proaktive Fähigkeiten. Durch die dynamische Einbindung von Konfigurationsinformationen, Systemarchitektur und Abhängigkeiten können Erklärungen deutlich spezifischer und handlungsrelevanter gestaltet werden. Dies umfasst die: Automatische Extraktion relevanter Konfigurationsparameter, Integration von Systemarchitekturwissen und Berücksichtigung von Service-Interaktionen und Abhängigkeiten.\n",
        "\n",
        "### Interaktive Fehleranalyse\n",
        "\n",
        "Entsprechend dem Vorschlag des Product Owners zur Erweiterung des Systems um interaktive Funktionen: \\> \"Weiterentwicklung: interaktiver: z.B. in die Erklärung ein Chatfenster → KI nochmal Nachfragen stellen\" (P)\n",
        "\n",
        "Das System kann um einen dialogorientierten Ansatz erweitert werden, bei dem Benutzer Rückfragen zu Erklärungen stellen können. Dies unterstützt den Übergang zu einem proaktiveren System durch:\n",
        "\n",
        "-   **Vertiefende Erklärungen:** Detailliertere Informationen zu spezifischen Aspekten eines Fehlers\n",
        "\n",
        "-   **Schrittweise Fehleranalyse:** Geführte Exploration der Fehlerursachen\n",
        "\n",
        "-   **Kontextualisierte Lösungsvorschläge:** Anpassung der Lösungsvorschläge an die spezifische Situation des Benutzers\n",
        "\n",
        "## Technische Verbesserungen und Priorisierung\n",
        "\n",
        "Die Evolution zu einem selbstlernenden System erfordert zusätzliche Komponenten und eine priorisierte Umsetzung. Basierend auf den Experteninterviews, der technischen Machbarkeit und dem erwarteten Wertbeitrag wird folgende Implementierungsstrategie vorgeschlagen:\n",
        "\n",
        "**Hohe Priorität:**\n",
        "\n",
        "-   Systemkontext-Integration: Implementierung eines Systemkontext-Connectors zur dynamischen Einbindung von CAS-Komponenten und Konfigurationsinformationen\n",
        "\n",
        "-   Einfacher Feedback-Mechanismus: Einführung eines \"Hilfreich/Nicht hilfreich\"-Buttons mit Feedback-Datenbank zur Bewertungsspeicherung\n",
        "\n",
        "-   BlueBox-übergreifender Wissenstransfer: Entwicklung von Mechanismen zur Dokumentation und Wiederverwendung erfolgreicher Fehlerbehebungen\n",
        "\n",
        "**Mittlere Priorität:**\n",
        "\n",
        "-   Verbesserte Fehlerkategorisierung und Cluster-Erkennung mittels Analyse-Engine\n",
        "\n",
        "-   Konfigurationsempfehlungen basierend auf historischen Daten\n",
        "\n",
        "-   Erweiterter Prompt-Generator mit interaktiver Chatbot-Funktionalität\n",
        "\n",
        "Diese inkrementelle Umsetzungsstrategie gewährleistet, dass jede Implementierungsphase einen konkreten Mehrwert liefert und gleichzeitig die Grundlage für nachfolgende Erweiterungen schafft.\n",
        "\n",
        "\n",
        "# Fazit\n",
        "\n",
        "## Zusammenfassung der Forschungsergebnisse\n",
        "\n",
        "Diese Arbeit untersuchte die Evolution eines LLM-basierten Fehlererklärungssystems zu einem selbstlernenden System durch systematische Analyse und Feedback. Durch den Feed-Forward/Feed-Backward-Ansatz wurden theoretische Grundlagen, praktische Implementierung und ein evolutionäres Weiterentwicklungskonzept erarbeitet.\n",
        "\n",
        "Die zentralen Ergebnisse sind:\n",
        "\n",
        "1.  **Erfolgreiche LLM-Integration:** Die CASGPT-Implementierung demonstriert die effektive Nutzung von LLMs zur Verbesserung der Benutzererfahrung bei komplexen Cloud-Deployments (Brown et al., 2020; Wang et al., 2023).\n",
        "2.  **Systemkontext als kritische Limitierung:** Die Evaluation identifizierte mangelnden Systemkontext als zentrale Einschränkung, was die Notwendigkeit einer dynamischen Kontextintegration unterstreicht (Talukdar & Biswas, 2023).\n",
        "3.  **MAPE-K als Evolutionsrahmen:** Das MAPE-K-Framework bietet ein strukturiertes Modell für die Evolution zu einem selbstlernenden System (Cheng et al., 2009; Wong et al., 2022).\n",
        "4.  **Proaktive Fähigkeiten als Ziel:** Der konzipierte Übergang von reaktiven Erklärungen zu proaktiven Empfehlungen und Fehlervorhersagen zeigt das Potenzial der Kombination von LLMs mit Mustererkennungstechniken (Vorobyov et al., 2021; Wang et al., 2022).\n",
        "\n",
        "Diese Ergebnisse adressieren direkt die Hauptforschungsfrage zur Evolution eines LLM-basierten Fehlererklärungssystems zu einem selbstlernenden System und liefern konkrete Konzepte für die praktische Umsetzung.\n",
        "\n",
        "## Praktische Implikationen\n",
        "\n",
        "Die Forschungsergebnisse haben wichtige praktische Implikationen für Organisationen:\n",
        "\n",
        "-   Bereits ein Basissystem ohne umfassenden Systemkontext bietet durch verbesserte Transparenz einen Mehrwert für Benutzer und Organisationen. Die Experteninterviews bestätigten, dass selbst generische Erklärungen zu einem besseren Verständnis komplexer Fehlermeldungen beitragen können.\n",
        "-   Die schrittweise Evolution ermöglicht einen inkrementellen Ansatz mit kontinuierlichem Wertbeitrag. Organisationen können mit grundlegenden Funktionen beginnen und das System systematisch erweitern, ohne umfangreiche Vorabinvestitionen.\n",
        "-   Feedback ist die Schlüsselressource für den Übergang zu selbstlernenden Systemen. Die konsequente Sammlung und Analyse von Benutzerfeedback bildet die Grundlage für kontinuierliche Verbesserung und Adaptation.\n",
        "\n",
        "Diese Implikationen gelten nicht nur für Fehlererklärungssysteme, sondern können auf weitere KI-gestützte Assistenzsysteme in Enterprise-Umgebungen übertragen werden (Devaraju, 2024; Perron et al., 2025).\n",
        "\n",
        "## Limitationen und kritische Reflexion\n",
        "\n",
        "Diese Arbeit unterliegt mehreren Limitationen:\n",
        "\n",
        "-   **Prototypischer Charakter:** Das volle Potenzial des Systems würde sich erst im langfristigen produktiven Einsatz zeigen. Die tatsächliche Nutzungserfahrung könnte zu weiteren Erkenntnissen führen, die im Rahmen dieser Arbeit nicht antizipiert werden konnten.\n",
        "-   **Konzeptionelle vs. implementierte Evolution:** Das Weiterentwicklungskonzept wurde theoretisch ausgearbeitet, aber nicht vollständig implementiert. Die praktische Umsetzung könnte zusätzliche Herausforderungen offenbaren, die weitere Anpassungen erfordern.\n",
        "-   **Generalisierbarkeit:** Die Ergebnisse beziehen sich spezifisch auf den CAS-Kontext und Deployment-Fehler im Cloud-Umfeld. Obwohl die grundlegenden Prinzipien übertragbar sein dürften, können in anderen Domänen spezifische Anpassungen erforderlich sein.\n",
        "\n",
        "## Ausblick\n",
        "\n",
        "Diese Forschung eröffnet mehrere vielversprechende Richtungen für zukünftige Arbeit:\n",
        "\n",
        "-   **Erweiterte Lernmethoden:** Integration von Reinforcement Learning from Human Feedback (RLHF) (Stiennon et al., 2020) und ausgereifteren Human-in-the-Loop-Ansätzen (Wu et al., 2022). Diese könnten die Adaptivität des Systems weiter verbessern und den Übergang zu einem vollständig selbstlernenden System beschleunigen.\n",
        "-   **Multi-Agent-Systeme:** Verteilte Fehleranalyse durch spezialisierte Agenten für verschiedene Aspekte der Systemdiagnose. Dieses Konzept könnte die Skalierbarkeit und Spezifität der Fehleranalyse verbessern, indem verschiedene Agenten für unterschiedliche Systemkomponenten oder Fehlertypen spezialisiert werden.\n",
        "-   **Domänenadaption:** Übertragung des Konzepts auf andere Cloud-Plattformen und Deployment-Umgebungen. Die generischen Prinzipien des Feed-Forward/Feed-Backward-Ansatzes und der systematischen Evolution könnten auf andere technische Domänen angewendet werden.\n",
        "-   **Balance zwischen Erklärbarkeit und Leistungsfähigkeit:** Weitere Forschung zur optimalen Balance zwischen detaillierten, transparenten Erklärungen und effizienter, prägnanter Kommunikation ist notwendig. Dies betrifft insbesondere die Frage, wie viel Kontext und technisches Detail für verschiedene Benutzergruppen hilfreich ist.\n",
        "-   **Vertrauen in KI-generierte Erklärungen:** Untersuchung der Faktoren, die das Vertrauen in LLM-generierte technische Erklärungen beeinflussen. Die Akzeptanz solcher Systeme hängt maßgeblich vom Vertrauen der Benutzer ab, was weitere Forschung zu Transparenz, Konsistenz und Nachvollziehbarkeit erfordert.\n",
        "\n",
        "Die Evolution von LLM-basierten Assistenzsystemen steht noch am Anfang. Diese Arbeit liefert einen Beitrag durch die systematische Untersuchung der Integration und Evolution eines spezifischen Anwendungsfalls, bietet jedoch gleichzeitig einen konzeptionellen Rahmen für die weitere Erforschung selbstlernender KI-Systeme in Enterprise-Umgebungen.\n",
        "\n",
        "\n",
        "\n",
        "<!-- Anhang ### Den folgenden Code-Block nicht entfernen!!!  -->\n",
        "\n",
        "\\appendix\n",
        "\\renewcommand{\\thefigure}{A\\arabic{figure}}\n",
        "\\renewcommand{\\thetable}{A\\arabic{table}}\n",
        "\\setcounter{figure}{0}\n",
        "\\setcounter{table}{0}\n",
        "\n",
        "# Anhang\n",
        "\n",
        "## User Interface\n",
        "\n",
        "![](img/JSON.png)\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## detailliertes Komponenten Diagramm\n",
        "\n",
        "![](img/KomponentenDiagrammDetailliert.png)\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Prompt-Engineering Workflow\n",
        "\n",
        "![](img/PromptEngineeringWorkflow.png)\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Chancen und Herausforderungen bei der Integration von LLMs in Enterprise-Systemen\n",
        "\n",
        "+-------------------------------+---------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
        "| **Chancen**                   | **Beschreibung**                                                    | **Herausforderungen:**                                                                         |\n",
        "|                               |                                                                     |                                                                                                |\n",
        "|                               |                                                                     | **Beschreibung**                                                                               |\n",
        "+===============================+=====================================================================+================================================================================================+\n",
        "| Automati-\\                    | Reduktion manueller Prozesse durch natürlichsprachliche Interaktion | **Sicherheit**: Schutz sensibler Daten und Konformität mit Zero-Trust-Architektur (Dash, 2024) |\n",
        "| sierung                       |                                                                     |                                                                                                |\n",
        "+-------------------------------+---------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
        "| Verbesserte Benutzererfahrung | Vereinfachung komplexer technischer Inhalte                         | **Ressourcenbedarf**: Hohe Anforderungen an Rechenleistung und Speicher (Hu et al., 2021)      |\n",
        "+-------------------------------+---------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
        "| Wissens-                      | Demokratisierung von Expertenwissen                                 | **Datenschutz & Compliance**: Einhaltung von Regularien wie DSGVO (Devaraju, 2024)             |\n",
        "|                               |                                                                     |                                                                                                |\n",
        "| distribution                  |                                                                     |                                                                                                |\n",
        "+-------------------------------+---------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
        "| Integrations-                 | Brückentechnologie zwischen verschiedenen Systemen                  | **Interpretierbarkeit**: Nachvollziehbarkeit von Entscheidungen (Kumar et al., 2025)           |\n",
        "|                               |                                                                     |                                                                                                |\n",
        "| fähigkeit                     |                                                                     |                                                                                                |\n",
        "+-------------------------------+---------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
        "| Skalier-                      | Bewältigung wachsender und diverser Fehlertypen                     | **Wartbarkeit**: Kontinuierliche Anpassung und Optimierung (Alibakhsh, 2023)                   |\n",
        "|                               |                                                                     |                                                                                                |\n",
        "| barkeit                       |                                                                     |                                                                                                |\n",
        "+-------------------------------+---------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Vergleich verschiedener Fehlererklärungsansätze\n",
        "\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| **Ansatz**                       | **Beschreibung**                      | **Stärken**    | **Schwächen**                           | **Relevanz für CASGPT**   |\n",
        "+==================================+=======================================+================+=========================================+===========================+\n",
        "| **Traditionelle Ansätze**        |                                       |                |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| Statische Fehlercodes            | Standardisierte Fehlermeldungen       | Konsis-\\       | Kontextlosigkeit, schwer verständlich   | Baseline für Verbesserung |\n",
        "|                                  |                                       | tenz           |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| Dokumen-\\                        | Umfassende Fehlerbeschreibungen       | Detailtiefe    | Wartungs-\\                              | Ergänzende Wissensquelle  |\n",
        "| tationen                         |                                       |                | aufwand,\\                               |                           |\n",
        "|                                  |                                       |                | Veraltung                               |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| Rule-Based Error Handling        | Regelbasierte Fehlerbehandlung        | Präzision bei\\ | Schlechte Skalierbarkeit                | Ergänzender Ansatz        |\n",
        "|                                  |                                       | bekannten\\     |                                         |                           |\n",
        "|                                  |                                       | Fehlern        |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| **KI-basierte Ansätze**          |                                       |                |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| Case-Based Reasoning             | Lösung basierend auf ähnlichen Fällen | Praxis-\\       | Abhängigkeit von Fallbasis              | Konzeptuelle Ähnlichkeit  |\n",
        "|                                  |                                       | bewährte\\      |                                         |                           |\n",
        "|                                  |                                       | Lösungen       |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| ML-Clustering                    | Musterbasierte Fehlerkategorisierung  | Automa-\\       | Keine natürlichsprachlichen Erklärungen | Ergänzende Technik        |\n",
        "|                                  |                                       | tische\\        |                                         |                           |\n",
        "|                                  |                                       | Gruppie-\\      |                                         |                           |\n",
        "|                                  |                                       | rung           |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "| LLM-basierte Root Cause Analysis | LLM-gestützte Ursachenanalyse         | Natürlich-\\    | Halluzinationen, Ressourcenbedarf       | Direktes Vorbild          |\n",
        "|                                  |                                       | sprachliche\\   |                                         |                           |\n",
        "|                                  |                                       | Erklärungen,\\  |                                         |                           |\n",
        "|                                  |                                       | Adaptivität    |                                         |                           |\n",
        "+----------------------------------+---------------------------------------+----------------+-----------------------------------------+---------------------------+\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Relevante Prompt-Patterns für Fehlererklärungen\n",
        "\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "| **Pattern**         | **Beschreibung**                                   | **Anwendung in CASGPT**                                                |\n",
        "+=====================+====================================================+========================================================================+\n",
        "| Persona Pattern     | Definition einer spezifischen Rolle für das LLM    | \"Du bist ein Experte für Fehlererklärung in Cloud-Deployment-Systemen\" |\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "| Template Pattern    | Vorgabe einer spezifischen Ausgabestruktur         | Strukturierung der Erklärung in Ursache, Auswirkung, Lösung            |\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "| Context Enhancement | Anreicherung mit domänenspezifischem Wissen        | Integration von Systemwissen über CAS-Komponenten                      |\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "| Cognitive Verifier  | Aufforderung zur Verifizierung der eigenen Antwort | Selbstprüfung zur Reduktion von Halluzinationen                        |\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "| Reflection Pattern  | Explizite Aufforderung zur Selbstreflexion         | Erkennung von Unsicherheiten in der Erklärung                          |\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "| Chain-of-Thought    | Aufforderung zu schrittweisem Denken               | Verbesserung der Reasoning-Fähigkeiten des LLM                         |\n",
        "+---------------------+----------------------------------------------------+------------------------------------------------------------------------+\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Kernkonzepte selbstlernender Systeme für CASGPT\n",
        "\n",
        "+-------------------+------------------------------------------------------------------+--------------------------+------------------------------------------+\n",
        "| **Konzept**       | **Beschreibung**                                                 | **Relevanz für CASGPT**  | **Literatur**                            |\n",
        "+===================+==================================================================+==========================+==========================================+\n",
        "| MAPE-K Loop       | Monitor-Analyze-Plan-Execute-Knowledge-Zyklus für Selbstadaption | Strukturiertes\\          | Cheng et al. (2009)                      |\n",
        "|                   |                                                                  | Framework\\               |                                          |\n",
        "|                   |                                                                  | für den Feed-Forward/\\   |                                          |\n",
        "|                   |                                                                  | Feed-Backward-\\          |                                          |\n",
        "|                   |                                                                  | Kreislauf                |                                          |\n",
        "+-------------------+------------------------------------------------------------------+--------------------------+------------------------------------------+\n",
        "| Feedback-\\        | Systematische Rückkopplungsmechanismen                           | Grundlage für\\           | Kang & Meira-Goes (2022)                 |\n",
        "| Schleifen         |                                                                  | kontinuierliches Lernen\\ |                                          |\n",
        "|                   |                                                                  | aus Erfahrungen          |                                          |\n",
        "+-------------------+------------------------------------------------------------------+--------------------------+------------------------------------------+\n",
        "| Human-in-the-Loop | Integration menschlichen Feedbacks in den Lernprozess            | Verbesserung\\            | Wu et al. (2022); Stiennon et al. (2020) |\n",
        "|                   |                                                                  | der Erklärungs­qualität\\  |                                          |\n",
        "|                   |                                                                  | durch Expertenwissen     |                                          |\n",
        "+-------------------+------------------------------------------------------------------+--------------------------+------------------------------------------+\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Häufigkeit der wichtigsten Codes in den Interviews\n",
        "\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| **Code & Beschreibung**                   | **D**   | **M**   | **P**   | **Gesamt** |\n",
        "+===========================================+=========+=========+=========+============+\n",
        "| `EX_SYSTEM_CONTEXT_NEED`:\\                | 4       | 2       | 2       | **8**      |\n",
        "| Bedarf an mehr systemspezifischem Kontext |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| `EX_SPECIFICITY_LACK`:\\                   | 3       | 2       | 1       | **6**      |\n",
        "| Mangel an Spezifität in Erklärungen       |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| `VALUE_POTENTIAL`:\\                       | 2       | 2       | 2       | **6**      |\n",
        "| Einschätzung des zukünftigen Potenzials   |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| `USER_UNDERSTAND`:\\                       | 1       | 2       | 2       | **5**      |\n",
        "| Beitrag zum Benutzerverständnis           |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| `INTEGRATION_POS`:\\                       | 1       | 1       | 1       | **3**      |\n",
        "| Positive Bewertung der Integration        |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| `VALUE_CURRENT_POS`:\\                     | 0       | 2       | 1       | **3**      |\n",
        "| Positive Bewertung des aktuellen Nutzens  |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "| `SELF_LEARN`:\\                            | 1       | 2       | 0       | **3**      |\n",
        "| Vorschläge zur Selbstlernfähigkeit        |         |         |         |            |\n",
        "+-------------------------------------------+---------+---------+---------+------------+\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Evolution von CASGPT - Vergleich Ist- und Zielzustand\n",
        "\n",
        "+--------------+--------------------------------+------------------+----------------------------------------------+\n",
        "| **Merkmal**  | **Aktueller Zustand**          | **Zielzustand**  | **Theoretische Grundlage**                   |\n",
        "+==============+================================+==================+==============================================+\n",
        "| Kontext-\\    | Generische Erklärungen         | Spezifische\\     | Wang et al. (2023); Kumar et al. (2025)      |\n",
        "| sensitivität |                                | Erklärungen mit\\ |                                              |\n",
        "|              |                                | Systemkontext    |                                              |\n",
        "+--------------+--------------------------------+------------------+----------------------------------------------+\n",
        "| Adaptivität  | Statische Prompt-Konfiguration | Kontinu-\\        | Ouyang et al. (2022); Stiennon et al. (2020) |\n",
        "|              |                                | ierliche\\        |                                              |\n",
        "|              |                                | Verbesserung\\    |                                              |\n",
        "|              |                                | durch Feedback   |                                              |\n",
        "+--------------+--------------------------------+------------------+----------------------------------------------+\n",
        "| Operations-\\ | Reaktiv: Nach Fehlerauftreten  | Proaktiv:\\       | Ahmed et al. (2023); Chen et al. (2023)      |\n",
        "| modus        |                                | Vorhersage\\      |                                              |\n",
        "|              |                                | und Vermeidung   |                                              |\n",
        "+--------------+--------------------------------+------------------+----------------------------------------------+\n",
        "| Inter-\\      | Einmalige Erklärung            | Dialog-basierte\\ | Wu et al. (2022)                             |\n",
        "| aktivität    |                                | Interaktion      |                                              |\n",
        "+--------------+--------------------------------+------------------+----------------------------------------------+\n",
        "| Lernfähig-\\  | Kein Lernen aus Erfahrung      | Systematisches\\  | Li et al. (2021); Wong et al. (2022)         |\n",
        "| keit         |                                | Lernen\\          |                                              |\n",
        "|              |                                | aus Feedback     |                                              |\n",
        "+--------------+--------------------------------+------------------+----------------------------------------------+\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Prompt Konfiguration Code\n",
        "\n",
        "Die ganze Datei `prompt_config.py` ist im digitalen Anhang zu finden.\n",
        "\n",
        "``` python\n",
        "# ...\n",
        "    def _initialize_system_prompt(self) -> str:\n",
        "        return \"\"\"You are an expert at explaining technical errors \n",
        "                  from Deutsche Telekom's deployment infrastructure.\n",
        "            Focus on providing clear, actionable explanations that:\n",
        "            1. Accurately identify whether it's a system or \n",
        "            user-related issue.\n",
        "            2. Explain technical concepts in accessible language.\n",
        "            3. Describe practical impacts on the deployment process.\n",
        "\n",
        "            When explaining errors:\n",
        "            - Be specific rather than generic, BUT if the error is \n",
        "            truly unknown, provide GENERAL guidance.\n",
        "            - Use technical terms appropriately but explain their \n",
        "            meaning.\n",
        "            - Keep explanations focused and relevant to the \n",
        "            deployment context.\n",
        "            - Consider these potential keywords: {keywords}\n",
        "            - Identify and explain any specific components, services, \n",
        "            or technologies mentioned in the error message.\n",
        "            - Explain the meaning of any HTTP status codes \n",
        "            in the context of the error.\n",
        "            - Provide potential causes for THIS SPECIFIC error, \n",
        "            not just general causes for the category.\n",
        "            - If the error message suggests a solution \n",
        "            (e.g., \"retrying\"), explain that suggestion.\n",
        "\n",
        "            IF THE ERROR CATEGORY IS 'General':\n",
        "            - Acknowledge that the error is not in a specific \n",
        "            known category.\n",
        "            - STILL try to extract useful information from the \n",
        "            error message:\n",
        "                - Are there any recognizable keywords \n",
        "                (e.g., \"database,\" \"connection,\" \"timeout\")?\n",
        "                - Are there any error codes (e.g., \"503,\" \"404\")?\n",
        "                - Is there any mention of specific files, paths, \n",
        "                or URLs?\n",
        "            - Based on the extracted information, provide the \n",
        "            MOST LIKELY causes and potential troubleshooting steps.\n",
        "            - Suggest general troubleshooting steps that are \n",
        "            ALWAYS helpful:\n",
        "                - Check network connectivity.\n",
        "                - Verify service status.\n",
        "                - Check recent logs.\n",
        "                - Consult relevant documentation.\n",
        "            - Clearly state that further investigation may \n",
        "            be needed if the general guidance doesn't \n",
        "            resolve the issue.\n",
        "\n",
        "            Your goal is to help users understand what went wrong \n",
        "            and its implications for the deployment process, \n",
        "            EVEN if the error is unfamiliar.\"\"\"\n",
        "\n",
        "    def _initialize_response_templates(self) -> Dict[str, str]:\n",
        "        templates = {\n",
        "            \"standard\": \"\"\"Analyze this error from Deutsche \n",
        "                           Telekom's deployment infrastructure:\n",
        "            ERROR TYPE: {error_type}\n",
        "            CONTEXT: {context}\n",
        "            ERROR MESSAGE:\n",
        "            {error_message}\n",
        "\n",
        "            EXPLANATION:\n",
        "            [Provide a technical analysis focusing on:\n",
        "            - Root cause identification\n",
        "            - Specific component or service affected\n",
        "            - Technical process that failed]\n",
        "\n",
        "            IMPACT:\n",
        "            [Describe:\n",
        "            - Immediate system effects\n",
        "            - Process disruption\n",
        "            - Required actions]\"\"\",\n",
        "\n",
        "            \"with_quick_fix\": \"\"\"Analyze this {category} error:\n",
        "            ERROR TYPE:\n",
        "            {error_type}: {category_name} Issue\n",
        "            EXPLANATION:\n",
        "            [Explain the error in clear technical terms, \n",
        "            considering this context: {context}]\n",
        "            IMPACT:\n",
        "            [Describe the practical effect on the deployment \n",
        "            environment and any potential risks]\n",
        "            QUICK FIX:\n",
        "            [Provide one simple, immediate action the user \n",
        "            can take to address this issue]\n",
        "            Keep the explanation concise but informative. \n",
        "            Focus on clarity and practical implications.\"\"\",\n",
        "\n",
        "            \"user_error\": \"\"\"Analyze this {category} error:\n",
        "            ERROR TYPE:\n",
        "            {error_type}: {category_name} Issue\n",
        "            EXPLANATION:\n",
        "            [Explain the error in clear technical terms, \n",
        "            considering this context: {context}]\n",
        "            IMPACT:\n",
        "            [Describe the practical effect on the \n",
        "            deployment environment]\n",
        "            USER ACTIONS:\n",
        "            {user_actions}\n",
        "            SUPPORT INFORMATION:\n",
        "            {support_info}\n",
        "            Keep the explanation concise but informative. \n",
        "            Focus on actionable steps the user can take.\"\"\"\n",
        "        }\n",
        "        return templates\n",
        "```\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Client Creation Code\n",
        "\n",
        "Die ganze Datei `error_explanation_handler.py` ist im digitalen Anhang zu finden.\n",
        "\n",
        "``` python\n",
        "# ...\n",
        "class ErrorRequest(BaseModel):\n",
        "    error_message: str = Field(..., min_length=1, max_length=1000)\n",
        "\n",
        "class ExplanationResponse(BaseModel):\n",
        "    explanation: str\n",
        "    categories: list[str] = Field(default_factory=list)\n",
        "    components: list[str] = Field(default_factory=list)\n",
        "\n",
        "class ErrorExplanationHandler:\n",
        "    def __init__(self):\n",
        "        self.vault = VaultAccess()\n",
        "        self.ai_service = self._initialize_ai_service()\n",
        "        self.prompt_config = PromptConfig()\n",
        "\n",
        "    def _initialize_ai_service(self) -> AIService:\n",
        "        config = self._load_ai_service_config()\n",
        "        return AzureAIService(config)\n",
        "\n",
        "    def _load_ai_service_config(self) -> AIServiceConfig:\n",
        "        openai_key = self.vault.get_value(\n",
        "            self.vault.cas_kv_engine,\n",
        "            f\"{self.vault.cas_default_path}/utils\",\n",
        "            \"AZURE_OPENAI_KEY\"\n",
        "        )\n",
        "        if not openai_key:\n",
        "            raise ValueError(\"AI service key not found in vault\")\n",
        "\n",
        "        return AIServiceConfig(\n",
        "            endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', '').strip(),\n",
        "            api_key=openai_key,\n",
        "            deployment_name=os.getenv('DEPLOYMENT_NAME', '').strip(),\n",
        "            max_tokens=int(os.getenv('MAX_TOKENS', '200')),\n",
        "            temperature=float(os.getenv('TEMPERATURE', '0.7')),\n",
        "            proxy_url=os.getenv('PROXY_URL'),\n",
        "            request_timeout=float(os.getenv('REQUEST_TIMEOUT', \n",
        "                                            '30.0'))\n",
        "        )\n",
        "\n",
        "    async def get_error_explanation(self, error_request: \n",
        "                                    ErrorRequest) -> \n",
        "                                    ExplanationResponse:\n",
        "        try:\n",
        "            explanation = await self._get_ai_explanation\n",
        "                                (error_request.error_message)\n",
        "            categories = self.prompt_config.identify_error_categories\n",
        "                                        (error_request.error_message)\n",
        "\n",
        "            return ExplanationResponse(\n",
        "                explanation=explanation,\n",
        "                categories=[cat.name for cat in categories],\n",
        "                components=self._extract_related_components\n",
        "                                (explanation)\n",
        "            )\n",
        " # ...\n",
        "```\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Interviewnotizen\n",
        "\n",
        "1\\. \\*\\*D:\\*\\*\n",
        "\n",
        "Wer bist du bzw. welche Rolle hast du im CAS Projekt /\n",
        "welche Jobbeschreibung hast du?\n",
        "\n",
        "- DevOps Engineer (macht kein DevOps) → ist Backend Engineer\n",
        " - kümmert sich größtenteils um einen Orchestrator im\n",
        "Kubernetes Cloud Umfeld für CNFs\n",
        " - deployt automatisch das System, was die Blueboxen\n",
        "automatisch installiert\n",
        "\n",
        "Wie bewertest du die Qualität der KI-generierten Erklärungen?\n",
        "\n",
        "- zu generisch, es wird das erklärt, was da steht aber\n",
        "klipp und klare Antworten wären besser\n",
        "\n",
        "Kannst du ein konkretes Beispiel für eine besonders gelungene /\n",
        "weniger gelungene Erklärung nennen?\n",
        "\n",
        "- …Object of type Exception is not JSON serializable\n",
        "\n",
        "Wie gut integriert sich das Feature in den bestehenden Workflow?\n",
        "\n",
        "- vorausgesetzt die BlueBoxen benutzen das ProgressView\n",
        "→ super Integration\n",
        " - nicht zu hohe Latenz zwischen der Antwort\n",
        " - im besten Fall gibt es nicht zu viele Fehler und\n",
        "wenn man so ca. 5 Sekunden wartet ist’s okay\n",
        "\n",
        "Gibt es Verbesserungspotenzial bei der Integration?\n",
        "\n",
        "- Ja, die System Knowledge fehlt,\n",
        "die man in die Prompts einbauen sollte\n",
        "- mehr Custom Knowledge\n",
        "\n",
        "Wie schätzt du den Gesamtnutzen des Features ein?\n",
        "\n",
        "- jetzt grade: noch nicht allzu hoch\n",
        " - mit Verbesserung besser\n",
        " - sehr viel Potenzial → tatsächliche Zeitersparnis\n",
        "auf unserer Seite + BlueBox Seite\n",
        "\n",
        "Welche Verbesserungsvorschläge hast du für die Weiterentwicklung?\n",
        "\n",
        "- mehr Systemknowledge + Pormpts mit mehr Informationen füllen\n",
        "- User oder Systemfehler kategorisieren\n",
        " - du kannst dafür nichts, das betroffene System kann sich nicht\n",
        "zu dem System connecten, Tipp: connectivity issues können\n",
        "durch retry vermieden werden\n",
        "- vielleicht noch nicht jetzt, aber wenn die Prompts mit\n",
        "Systeminfo gefüllt werden würden, würden die Kunden Infos bekommen,\n",
        "wie die Services funktionieren, besser als sie jemals wissen könnten\n",
        " - Hilfe bekommen ohne Dokumentation zu lesen\n",
        "(die es nicht gibt :) )\n",
        " - wir hätten die Möglichkeit die Fehler zu erkennen\n",
        "→ Prompts umschreiben um zusätzliche Informationen\n",
        "mit reinzuschreiben\n",
        " - wenn Fehler bei einer anderen BlueBox war, direkt in Prompt\n",
        "mit schreiben: das war übrigens der Fix\n",
        "→ BlueBox kann das selber machen\n",
        " - Spart Zeit → weniger Supportaufwand bei selbem Fehler\n",
        "\n",
        "Gibt es noch Aspekte, die wir nicht besprochen haben?\n",
        "\n",
        "- Datenschutz abgedeckt, keine User spezifischen Sachen\n",
        "\n",
        "Gewünschte Fehlererklärung & Kontext, wie die Log Messages\n",
        "erstellt werden:\n",
        "\n",
        "- unhandled expection was caught → müsste übergeben werden,\n",
        "kommt aus unseren Services → viel genauer: wir haben 200 erwartet,\n",
        "in den Klammern, was wir bekommen haben,\n",
        "nur eine Log Message auswerten\n",
        "- das in den Klammern, was ich tatsächlich bekommen habe,\n",
        "die Erklärung dass unser Service einen anderen Service\n",
        "kontaktiert hat, der mit dem Fehlercode\n",
        "“Internal server error: object of type …)\n",
        " - unsere Services schreiben Logs mit den ähnlichen / gleichen ids\n",
        "→ Service der das wiederbekommt -\\> der eine Service hat den\n",
        "anderen kontaktiert und hat den Fehler bekommen\n",
        "- an unhandled exepception was caught → von den Systeminfos, was\n",
        "unsere Services produzieren / schreiben → die Services sind in\n",
        "folgende Fehler gelaufen\n",
        "1. \\*\\*M:\\*\\*\n",
        "\n",
        "Wer bist du bzw. welche Rolle hast du im CAS Projekt /\n",
        "welche Jobbeschreibung hast du?\n",
        "\n",
        "- Software Engineer - Full-Stack: Frontend, Backend,\n",
        "vor allem Frontend\n",
        "- alles was mit dem CAS Portal zutun hat\n",
        "\n",
        "Wie bewertest du die Qualität der KI-generierten Erklärungen?\n",
        "Kannst du ein konkretes Beispiel für eine besonders gelungene /\n",
        "weniger gelungene Erklärung nennen?\n",
        "\n",
        "- doch schon einiges an Hilfe, nicht jeder User weiß, was ein DSO ist\n",
        "- wenn ich persönlich erklären würde, würde ich auch vorlesen und\n",
        "darauf erklären\n",
        " - doppelt da stehen ist nicht kritisch aber garkeine neue Info,\n",
        "ist schade\n",
        " - manchmal lässt es sich nicht verhindern,\n",
        "teilweise recht selbstaussagend\n",
        "- Qualität ist für den Datenumfang gut, man merkt, die KI versteht,\n",
        "worum es geht, wahrscheinlich weil System prompt gut gesgnined ist\n",
        " - verbessern mit mehr Daten geht immer, Grundidee ist gut,\n",
        "absolut ausreichend\n",
        " - DSO erklärt und sowas anderes reicht einem User der\n",
        "nicht technisch versiert ist, zu verstehen worum es geht\n",
        "\n",
        "Inwieweit unterstützt das Feature den Deployment-Prozess?\n",
        "\n",
        "- den Prozess an sich nicht, aber den User, insoweit,\n",
        "dass der User besser versteht, was der Fehler ist und evtl.\n",
        "vermeiden wir einfache Fehler zu großen Problemen werden\n",
        " - User versteht “ah ok war keine Verbindung zu wo auch immer”\n",
        " - Open Telekom Cloud nicht erreichbar → Systemfehler\n",
        "\n",
        "Wie gut integriert sich das Feature in den bestehenden Workflow?\n",
        "\n",
        "- perfekt, den Button finde ich gut, aufklappbar,\n",
        "besser geht fast garnicht, genau richtig\n",
        "\n",
        "Wie beurteilst du die \\*Qualität der Erklärungen im Hinblick auf\n",
        "technische Korrektheit und Vollständigkeit\\*\n",
        "\n",
        "- damit sie besser wird, muss man mehr Daten einfügen,\n",
        "mehr Daten = bessere Antworten\n",
        "\n",
        "Wie schätzt du den Gesamtnutzen des Features ein?\n",
        "\n",
        "- aktuell: viel Wiederholung, manchmal reicht dem User,\n",
        "dass er sieht, der error ist erklärbar\n",
        "→ gutes Gewissen, Transparenz wird geschaffen\n",
        " - Qualität der Antworten kommt mit der Skalierung\n",
        " - aktuell ein nice to have\n",
        " - und man kann sagen “man nutzt AI”: alleine dafür gut\n",
        "\n",
        "Welche Verbesserungsvorschläge hast du für die Weiterentwicklung?\n",
        "\n",
        "- selbstlernend immer sinnvoll → Antwortsqualität bewerten,\n",
        "anstatt dass es sich selbst mit schwachen Antworten füttert\n",
        " - wenn System Knowledge (Wiki Dump) dem Model gegeben wird,\n",
        "hat es mehr Ahnung worum es geht\n",
        " - Fehlermeldungen sammeln, bestmögliche Antwort\n",
        "auswählen vom Model bewerten\n",
        " - Fíne-Tuning\n",
        "- mehr Daten, Struktur finde ich gut,\n",
        "Weiternetwicklung auf andere Sachen\n",
        " - Logging Seite, in Zukunft kommt bestimmt mehr dazu\n",
        " - guter Einstieg\n",
        " - man weiß, wie man ans Modell kommt\n",
        "\n",
        "Gibt es noch Aspekte, die wir nicht besprochen haben?\n",
        "\n",
        "- wie ist es aktuell, du nimmst die error message\n",
        "direkt von der Seite?\n",
        " - könnte man da cross scripten?\n",
        "- Warum ist das ganze sinnvoll mit Ai zu lösen?\n",
        " - immer andere Fehlermeldung\n",
        " - Erweiterungspotenzial rechtfertigt das\n",
        "1. \\*\\*P:\\*\\*\n",
        "\n",
        "Wer bist du bzw. welche Rolle hast du im CAS Projekt /\n",
        "welche Jobbeschreibung hast du?\n",
        "\n",
        "- im CAS Projekt Squadlead im CAS Team\n",
        "→ Product Owner für Plattformlösung\n",
        " - verschiedene Automatisierungsprojekte innerhalb Telekom T-VM\n",
        " - generische Lösung Plattform für verschiedene Kundenprojekte\n",
        " - Verantwortung für das ganze Team &\n",
        "Plattformlösung & Kundenprojekte aufteilen\n",
        "\n",
        "Wie bewertest du die Qualität der KI-generierten Erklärungen?\n",
        "Kannst du ein konkretes Beispiel für eine besonders gelungene /\n",
        "weniger gelungene Erklärung nennen?\n",
        "\n",
        "- von dem was bisher gesehen: bisher unterschiedlich, erwartbar\n",
        "- gefühl, dass die Antworten je genereller das Problem,\n",
        "desto besser werden die Antworten\n",
        " - beispiel: string value im yml file nicht geparsed \\\n",
        "werden konnte\n",
        "→ fehler: text sollte verwendet werden\n",
        " - System kann das ganz gut\n",
        " - Infrastruktur zugeschnittene Dinge: schwieriger, \\\n",
        "Meta Daten nicht\n",
        " - unterschiedlich aber erwartbar\n",
        "\n",
        "Inwieweit unterstützt das Feature den Deployment-Prozess?\n",
        "\n",
        "- am Ende des Prozesses, Benutzer kann in der Progress view sehen,\n",
        "welche schritte abgehandelt werden in der zeit, sieht die Fehler\n",
        " - an dem Punkt setzt das feature an, Nutzer die nicht\n",
        "so tief technologisches verständnis haben\n",
        " - sehr technische Fehlermeldugnen können trotzdem\n",
        "angezeigt werden + erklärt werden\n",
        " - Qualität ganz gut unterwegs, manchmal geht es dazu\n",
        "Zusatzinformationen zu geben\n",
        " - manchmal in html / xml code eingebettet\n",
        " - Button click → Fehler wird auseinander genommen\n",
        " - \\*\\*Wertschöpfung: für Menschen komisch wirkenden\n",
        "Fehler in natürliche Sprache übersetzten\n",
        "→ einleuchtend und gern angucken\\*\\*\n",
        " - User hat oft keine Lust,\n",
        "sich das alles anzuschauen\n",
        "\n",
        "Wie gut integriert sich das Feature in den bestehenden Workflow?\n",
        "\n",
        "- eigentlich genauso integriert, funktioniert genauso wie ich mir\n",
        "so ein Feature wünschen würde\n",
        " - ich hab eine Fehlermeldung, klicke drauf und wird erklärt\n",
        " - wüsste nicht, was man das anders machen sollte, \\\n",
        "Integration gelungen\n",
        "- Integration absolut sinnvoll\n",
        "\n",
        "Gibt es Verbesserungspotenzial bei der Integration?\n",
        "\n",
        "- Content: mehr Informationen geben auf spezielle Infrastruktur\n",
        " - manchmal Nachrichten abgeschnitten\n",
        "(LLM zu kleine Token Größe eingestellt)\n",
        "→ da sollte man nacharbeiten\n",
        "\n",
        "Inwiefern erfüllt das Feature deine ursprüngliche Vision?\n",
        "Welche Aspekte haben dich positiv/negativ überrascht?\n",
        "\n",
        "- positiv gestimmt: so funktioniert, wie vorgestellt\n",
        " - hab das Gefühl, dass die Idee mit den verfügbaren Mitteln\n",
        "gut umgesetzt wurde\n",
        " - nicht positiv überrascht → positiv gestimmt\n",
        "- positiv überrascht: wie gut diese generellen Modelle auf diese\n",
        "speziellen tasks performen\n",
        " - wohl bewusst, das Meta Informationen zugegeben werden\\\n",
        "müssen um das zu verbessern\n",
        " - ohne besonderes training, einige dinge dabei, \\\n",
        "die gut funktionieren\n",
        "- positiv überrascht: wie gut man über Prompting \\\n",
        "die Antworten strukturieren kann\n",
        " - Prompts so geschrieben, dass sie verschieden strukturiert sind\n",
        " - entsprechende Strukturen, gleichbleibende Notation /\n",
        "Struktur der Antworten\n",
        "\n",
        "Wo siehst du das größte Potenzial für die Weiterentwicklung?\n",
        "\n",
        "- vorher Besprochen: content\n",
        "\n",
        "Wie schätzt du den Gesamtnutzen des Features ein?\n",
        "\n",
        "- Basierend auf den technischen Möglichkeiten des Nutzers,\n",
        "durchaus komplexe Fehlermeldungen verständlich zu erklären\n",
        "→ damit auch, das größere Ziel dahinter:\n",
        " - Support Anfragen an Plattformbetreiber reduzieren\n",
        "→ dem Nutzer zu zeigen, wer am ende für ein Fehler \\\n",
        "verantwortlich ist\n",
        " - z.B. in einer Parameter config kann ich den Fehler lösen \\\n",
        "(String erwartet)\n",
        " - für uns reduzieren wir als Plattformbetreiber die \\\n",
        "Supportanfragen\n",
        "\n",
        "Welche Verbesserungsvorschläge hast du für die Weiterentwicklung?\n",
        "\n",
        "- Weiterentwicklung: interaktiver: z.B., in die Erklärung \\\n",
        "ein Chatfenster\n",
        "→ KI nochmal Nachfragen stellen\n",
        " - man klappt das auf, kommt in Chatfenster und kann fragen,\n",
        "die Komponente cicd solution, was ist das überhaupt?\n",
        " - wem gehört das cas1ref cluster local?\n",
        " - um Antworten zu kriegen, für jeden User ist es anders,\n",
        "warum er die KI Erklärung haben will\n",
        " - der 1. User hat keine lust die Nachricht zu lesen \\\n",
        "und zu verstehen\n",
        " - der 2. User will verstehen, was überhaupt json ist / \\\n",
        "error code 500\n",
        "\n",
        "Gibt es noch Aspekte, die wir nicht besprochen haben?\n",
        "\n",
        "- unterschiedliche Modelle, super verschiedene Modelle,\n",
        "wir sind leider beschränkt was uns zur verfügung steht,\n",
        "über Tardis Integration nur Mistral / Llama zur Verfügung\n",
        " - evaluieren, inwieweit die Modelle, die man hat, performen \\\n",
        "→ bestes wählen\n",
        " - ggf. neu evaluieren\n",
        "\n",
        "Das Codebook für das Verschlagworten ist im digitalen Anhang zu finden.\n",
        "\n",
        "# Quellen\n",
        "\n",
        "1.  Abdallah, N., Mallouli, S., Sherif, I., Bahri, H., & Al-Fuqaha, A. (2024). Cloud Network Anomaly Detection Using Machine and Deep Learning Techniques— Recent Research Advancements.\n",
        "\n",
        "2.  Agrawal, V. (2016). Syntax errors identification from compiler error messages using ML techniques.\n",
        "\n",
        "3.  Ahmed, A., Sethi, S., Agarwal, P., Hossain, M. S., Azeem, A., & Gadekallu, T. R. (2023). Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models.\n",
        "\n",
        "4.  Alibakhsh, S. (2023). Challenges of Integrating LLMs Like ChatGPT with Enterprise Software and Solving it with Object Mess.\n",
        "\n",
        "5.  Bae, H., Seo, J., Kim, H., Kim, S., Park, J., & Kim, H. (2024). Enhancing Software Code Vulnerability Detection Using GPT-4o and Claude-3.5 Sonnet: A Study on Prompt Engineering.\n",
        "\n",
        "6.  Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. (2020). Language Models are Few-Shot Learners.\n",
        "\n",
        "7.  Chandramouli, R. (2022). Implementation of DevSecOps for a microservices-based application with service mesh.\n",
        "\n",
        "8.  Chen, Y., Yao, S., Yu, F., Wang, Y., Chen, J., Shen, B., ... & Zhou, P. (2023). Automatic Root Cause Analysis via Large Language Models for Cloud Incidents.\n",
        "\n",
        "9.  Chen, Y., Zehui, D., Sun, S., Chen, J., Yu, F., Jiang, Z., ... & Zhou, P. (2025). AIOpsLab: A Holistic Framework to Evaluate AI Agents for Enabling Autonomous Clouds.\n",
        "\n",
        "10. Cheng, B. H., de Lemos, R., Giese, H., Inverardi, P., Magee, J., Andersson, J., ... & Whittle, J. (2009). Software Engineering for Self-Adaptive Systems: A Research Roadmap.\n",
        "\n",
        "11. Cheng, X., Cheng, X., & Xu, B. (2024). Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains.\n",
        "\n",
        "12. Chukwuemeka Nwachukwu, C., Agboneni-Mordi, C. A., Igbinovia, P. A., Aniete, A. A., & Madu, C. A. (2024). AI-driven anomaly detection in cloud computing environments.\n",
        "\n",
        "13. Dash, S. (2024). Zero-Trust Architecture (ZTA): Designing an AI-Powered Cloud Security Framework for LLMs' Black Box.\n",
        "\n",
        "14. De Lemos, R., Giese, H., Müller, H. A., Shaw, M., Andersson, J., Litoiu, M., ... & Weyns, D. (2013). Software Engineering for Self-Adaptive Systems: A Second Research Roadmap.\n",
        "\n",
        "15. De Lemos, R., Garlan, D., Ghezzi, C., Giese, H., Andersson, J., Litoiu, M., ... & Schmerl, B. (2017). Software Engineering for Self-Adaptive Systems: Research Challenges in the Provision of Assurances.\n",
        "\n",
        "16. Detrois, M., Cito, J., Renggli, C., Agarwal, M., Karlaš, B., & Zhang, C. Automated processing of monitoring data for proactive root cause analysis in service-based systems.\n",
        "\n",
        "17. Devaraju, B. M. (2024). Architecting Scalable LLM-Powered Employee Engagement Systems: A Multi-Modal Framework for Enterprise Application Integration.\n",
        "\n",
        "18. Dhoopati, K. S. (2023). Enhancing Enterprise Application Integration through Artificial Intelligence and Machine Learning.\n",
        "\n",
        "19. Engström, E., Engström, J., Björn, L., & Pettersson, O. (2020). How software engineering research aligns with design science: a review.\n",
        "\n",
        "20. Happe, C., & Cito, J. (2025). Can LLMs Hack Enterprise Networks: Autonomous Assumed Breach Penetration-Testing Active Directory Networks.\n",
        "\n",
        "21. Hevner, A., & Chatterjee, S. (2010). Design Science Research in Information Systems.\n",
        "\n",
        "22. Hevner, A. R. (2007). A Three Cycle View of Design Science Research.\n",
        "\n",
        "23. Hevner, A. R., March, S. T., Park, J., & Ram, S. (2004). Design Science in Information Systems Research.\n",
        "\n",
        "24. Hu, F., Zhou, J., Ng, Y. P., & Chen, C. (2021). Pipeline Parallelism for Inference on Heterogeneous Edge Computing.\n",
        "\n",
        "25. Hussain, M. W., & Zaidi, U. S. (2024). AdaBoost Ensemble Approach with Weak Classifiers for Gear Fault Diagnosis and Prognosis in DC Motors.\n",
        "\n",
        "26. Kang, D., & Meira-Goes, J. (2022). Requirements Engineering for Feedback Loops in Software-Intensive Systems.\n",
        "\n",
        "27. Krishna, L. K., Sankaralingam, S., & Jayaram, S. (2023). An Enhanced Time Series Analysis to Improve the Performance of 5G Communication Systems.\n",
        "\n",
        "28. Kumar, S., Singh, V., Laxman, S., & Mishra, D. (2025). A multivariate transformer-based monitor-analyze-plan-execute (MAPE) autoscaling framework for dynamic cloud resources.\n",
        "\n",
        "29. Laigner, R., Kalinowski, M., Diniz, S., Barros, L., Cassino, C., Lins, M., ... & Lifschitz, S. (2021). Data management in microservices: state of the practice, challenges, and research directions.\n",
        "\n",
        "30. Li, Y., Luo, D., Hu, C., Zhang, Z., Wang, J., & Lu, S. (2024). Interpretable Analysis of Production GPU Clusters Monitoring Data via Association Rule Mining.\n",
        "\n",
        "31. Mao, X., Tang, J., Qiu, W., Liu, Y., Wang, X., & Li, Z. (2024). Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Technical Approaches.\n",
        "\n",
        "32. Mayring, P. (2014). Qualitative content analysis: theoretical foundation, basic procedures and software solution.\n",
        "\n",
        "33. Mosqueira-Rey, E., Hernández-Pereira, E., & Alonso-Ríos, D. (2023). Human-in-the-loop machine learning: a state of the art.\n",
        "\n",
        "34. Orgad, E., Maharshak, Y., Jain, S., Izsak, P., Gadre, S. Y., Pang, R. Y., ... & Hassid, Y. (2024). LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations.\n",
        "\n",
        "35. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., ... & Christiano, P. (2022). Training language models to follow instructions with human feedback.\n",
        "\n",
        "36. Oyekunle Claudius Oyeniran, O. C., Harapus, R., Adesola Akinade, B., & Nwangene, C. O. (2024). Microservices architecture in cloud-native applications: Design patterns and scalability.\n",
        "\n",
        "37. Peffers, K., Tuunanen, T., Rothenberger, M. A., & Chatterjee, S. (2007). A Design Science Research Methodology for Information Systems Research.\n",
        "\n",
        "38. Perron, J., Fernandez, A., Arbesfeld, E., Mao, H., Muennighoff, N., Golowich, N., ... & Nguyen, A. (2025). Demystifying Application Programming Interfaces (APIs): Unlocking the Power of Large Language Models.\n",
        "\n",
        "39. Ramamoorthi, K. Machine Learning Models for Anomaly Detection in Microservices.\n",
        "\n",
        "40. Rizvi, S. Z. H., Javed, A. R., Ahmed, S., Al-Khateeb, H., & Malik, S. U. R. (2024). LSTM-Based Autoencoder with Maximal Overlap Discrete Wavelet Transforms Using Lamb Wave for Anomaly Detection.\n",
        "\n",
        "41. Sain, M., Matyukhina, A., Rožanec, J. M., & Mladenić, D. (2024). Leveraging ChatGPT to Enhance Debugging: Evaluating AI-Driven Solutions in Software Development.\n",
        "\n",
        "42. Santolucito, M., Zhai, E., Dhodapkar, R., Shim, A., & Piskac, R. (2017). Synthesizing configuration file specifications with association rule learning.\n",
        "\n",
        "43. Saurabh Ashwinikumar Dave, B. D., Surya, J., & Kumar, R. (2024). Scalable Microservices for Cloud Based Distributed Systems.\n",
        "\n",
        "44. Sein, M. K., Henfridsson, O., Purao, S., Rossi, M., & Lindgren, R. (2011). Action Design Research.\n",
        "\n",
        "45. Senior Lead Software Engineer, Richmond, VA, USA, & Balakrishna, A. (2023). Optimizing Observability: A Deep Dive into AWS Lambda Logging.\n",
        "\n",
        "46. Stiennon, N., Ouyang, L., Wu, J., Ziegler, D. M., Lowe, R., Voss, C., ... & Christiano, P. Learning to summarize from human feedback.\n",
        "\n",
        "47. Talukdar, W., & Biswas, A. (2023). Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach.\n",
        "\n",
        "48. Tamanampudi, V. M. (2024). End-to-End ML-Driven Feedback Loops in DevOps Pipelines.\n",
        "\n",
        "49. Tarun Kaniganti, T., & Naga Sai Kiran, N. S. (2021). Architecting Resilient REST APIs: Leveraging AWS, AI, and Microservices for Scalable Data Science Applications.\n",
        "\n",
        "50. Törnberg, P. (2024). Best Practices for Text Annotation with Large Language Models.\n",
        "\n",
        "51. Tzanettis, G., Kavoussanakis, K., & Piotter, S. (2022). Data Fusion of Observability Signals for Assisting Orchestration of Distributed Applications.\n",
        "\n",
        "52. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is All You Need.\n",
        "\n",
        "53. Vatsal, L., & Dubey, M. (2024). A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks.\n",
        "\n",
        "54. Venable, J., Pries-Heje, J., & Baskerville, R. (2016). FEDS: a Framework for Evaluation in Design Science Research.\n",
        "\n",
        "55. Vorobyov, N., Ustinova, E., Koriagin, F., & Noskov, A. (2021). Parallel Version of the Framework for Clustering Error Messages.\n",
        "\n",
        "56. Wang, D., Wei, H., Nayel, M., & An, Y. (2022). Intelligent Software Service Configuration Technology Based on Association Mining.\n",
        "\n",
        "57. Wang, H., Zhang, M., Zhang, Z., Agarwal, A., Zhao, S., Huang, P., ... & Wong, W. E. (2023). Transformer Fault Diagnosis Method Based on Incomplete Data and TPE-XGBoost.\n",
        "\n",
        "58. Wang, J., Wei, J., He, H., Tian, C., & Chen, H. (2024). Research on Rolling Bearing Fault Diagnosis Method Based on ECA-MRANet.\n",
        "\n",
        "59. Wang, P., Peng, Z., Ding, Z., Zhang, B., Jiang, H., & Wang, Y. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models.\n",
        "\n",
        "60. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E. H., Le, Q., & Zhou, D. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.\n",
        "\n",
        "61. Weyns, D. (2019). Software Engineering for Self-adaptive Systems.\n",
        "\n",
        "62. White, J., Bommasani, R., & Gruver, N. (2023). A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT.\n",
        "\n",
        "63. Wong, S., Chua, Z. E., & Xumin, L. (2022). Self-Adaptive Systems: A Systematic Literature Review Across Categories and Domains.\n",
        "\n",
        "64. Wu, T., Jiang, L., Zheng, X., Ripple, A., Boucher, N., Shao, M. S., ... & Ma, S. (2022). A Survey of Human-in-the-loop for Machine Learning.\n",
        "\n",
        "65. Wu, Z., Jiang, S., Liu, Q., & Wang, H. (2024). Large Language Models Can Self-Correct with Key Condition Verification.\n",
        "\n",
        "66. Yasmin, A., Lano, K., & Alrajeh, D. (2020). A First Look at the Deprecation of RESTful APIs: An Empirical Study.\n",
        "\n",
        "67. Zhang, H., Liu, J., Wang, K., Zhong, W., Wang, A., Ma, M., ... & Chen, Y. (2024). Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4.\n",
        "\n",
        "68. Zhang, Y., Li, X., Bing, L., Wang, X., Shi, S., Yan, R., ... & Zhu, W. (2024). Comparison of Prompt Engineering and Fine-Tuning Strategies in Large Language Models in the Classification.\n",
        "\n",
        "69. Zhao, S., Zhu, X., Zhao, H., Jin, Y., Cui, Y., & Sun, C. (2024). CHASE: A Causal Heterogeneous Graph based Framework for Root Cause Analysis in Multimodal Microservices.\n",
        "\n",
        "# KI Tools zur Hilfe\n",
        "\n",
        "Anthropic. (2025). Claude 3.5 Sonnet \\[LLM\\]. (<https://claude.ai>)\n",
        "\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| Prompts                                                                                                                                             | Date accessed   |\n",
        "+=====================================================================================================================================================+=================+\n",
        "| \"Analysiere bitte die folgenden Fehlermeldungen, welchen Kontext brauchst du um diese besser beantworten zu können? (Beispiel Fehlermeldungen ...)\" | 22.01.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Erstelle eine Python-Klasse für ErrorCategory mit pattern matching und Gewichtung\"                                                                 | 24.01.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Wie implementiert man den Azure OpenAI Client für GPT-4 in Python in mit async Funktionen?\"                                                        | 26.01.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Konzept für State Management von einem Label in Angular, Button regelt das State Management des Labels?\"                                           | 30.01.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Wie verbindet man Frontend mit Backend über HTTP für AzureOpenAI API-Anfragen?\"                                                                    | 01.02.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Wie extrahiert man Keywords aus Fehlermeldungen mit RegEx für bessere LLM-Prompts?\"                                                                | 03.02.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Wie implementiere ich adaptive Response Templates je nach Fehlertyp (System vs. User Errors)\"                                                      | 05.02.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Wie strukturiert man einen System Prompt für technische Fehlererklärungen in natürlicher Sprache knapp aber detailliert erklärt?\"                  | 07.02.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
        "| \"Strategien für Error Pattern Matching mit gewichteten Regex-Mustern\"                                                                               | 09.02.2025      |\n",
        "+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+"
      ],
      "id": "07b896af"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/larsboes/.pyenv/versions/3.11.1/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}